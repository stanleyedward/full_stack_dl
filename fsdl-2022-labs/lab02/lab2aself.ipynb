{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://lightning.ai/docs/pytorch/stable/#get-started'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as pl\n",
    "pl.__version__\n",
    "\n",
    "docs_url = f'https://lightning.ai/docs/pytorch/stable/#get-started'\n",
    "docs_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pl.LightningModule` is a subclass of `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "issubclass(pl.LightningModule, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Generic PyTorch-Lightning class that must be initialized with a PyTorch module.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOSS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_cycle_max_lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_total_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_cycle_total_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_CYCLE_TOTAL_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0madd_to_argparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"optimizer class from torch.optim\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--one_cycle_max_lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--one_cycle_total_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mONE_CYCLE_TOTAL_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss function from torch.nn.functional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneCycleLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_total_steps\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lr_scheduler\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"monitor\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"validation/loss\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation/loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation/acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test/loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test/acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "from text_recognizer.lit_models import BaseLitModel\n",
    "\n",
    "BaseLitModel??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = torch.nn.Linear(in_features=1,\n",
    "                                     out_features=1)\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        return self.model(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/stanley/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'lightning' has no attribute 'utilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mexcept\u001b[39;00m pl\u001b[39m.\u001b[39mutilities\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mMisconfigurationException \u001b[39mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:937\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_logging_functions()\n\u001b[0;32m--> 937\u001b[0m _verify_loop_configurations(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    939\u001b[0m \u001b[39m# hook\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/configuration_validator.py:37\u001b[0m, in \u001b[0;36m_verify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n\u001b[0;32m---> 37\u001b[0m     __verify_train_val_loop_configuration(trainer, model)\n\u001b[1;32m     38\u001b[0m     __verify_manual_optimization_support(trainer, model)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/configuration_validator.py:57\u001b[0m, in \u001b[0;36m__verify_train_val_loop_configuration\u001b[0;34m(trainer, model)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_training_step:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m     58\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo `training_step()` method defined. Lightning `Trainer` expects as minimum a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m has_optimizers \u001b[39m=\u001b[39m is_overridden(\u001b[39m\"\u001b[39m\u001b[39mconfigure_optimizers\u001b[39m\u001b[39m\"\u001b[39m, model)\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: No `training_step()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     trainer\u001b[39m.\u001b[39mfit(model\u001b[39m=\u001b[39mmodel)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mexcept\u001b[39;00m pl\u001b[39m.\u001b[39;49mutilities\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mMisconfigurationException \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mtextwrap\u001b[39m.\u001b[39mwrap(\u001b[39mstr\u001b[39m(error), \u001b[39m80\u001b[39m), sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lightning' has no attribute 'utilities'"
     ]
    }
   ],
   "source": [
    "import logging #import some stdlb compenetes to control what's display \n",
    "import textwrap\n",
    "import traceback\n",
    "\n",
    "try:\n",
    "    logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    \n",
    "    trainer = pl.Trainer(accelerator='gpu' if torch.cuda.is_available() else 'cpu', max_epochs=1)\n",
    "    trainer.fit(model=model)\n",
    "    \n",
    "except pl.utilities.exceptions.MisconfigurationException as error:\n",
    "    print(\"Error:\", *textwrap.wrap(str(error), 80), sep='\\n\\t')\n",
    "    \n",
    "finally:\n",
    "    logging.getLogger(\"lightning\").setLevel(logging.INFO)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def training_step(self: pl.LightningModule, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "    xs, ys = batch  # unpack the batch\n",
    "    outs = self(xs)  # apply the model\n",
    "    loss = torch.nn.functional.mse_loss(outs, ys)  # compute the (squared error) loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "LinearRegression.training_step = training_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Here you compute and return the training loss and some additional metrics for e.g. the progress bar or\n",
      "logger.\n",
      "\n",
      "Args:\n",
      "    batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\n",
      "    batch_idx: The index of this batch.\n",
      "    dataloader_idx: The index of the dataloader that produced this batch.\n",
      "        (only if multiple dataloaders used)\n",
      "\n",
      "Return:\n",
      "    - :class:`~torch.Tensor` - The loss tensor\n",
      "    - ``dict`` - A dictionary. Can include any keys, but must include the key ``'loss'``.\n",
      "    - ``None`` - Skip to the next batch. This is only supported for automatic optimization.\n",
      "        This is not supported for multi-GPU, TPU, IPU, or DeepSpeed.\n",
      "\n",
      "In this step you'd normally do the forward pass and calculate the loss for a batch.\n",
      "You can also do fancier things like multiple forward passes or something model specific.\n",
      "\n",
      "Example::\n",
      "\n",
      "    def training_step(self, batch, batch_idx):\n",
      "        x, y, z = batch\n",
      "        out = self.encoder(x)\n",
      "        loss = self.loss(out, x)\n",
      "        return loss\n",
      "\n",
      "To use multiple optimizers, you can switch to 'manual optimization' and control their stepping:\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.automatic_optimization = False\n",
      "\n",
      "\n",
      "    # Multiple optimizers (e.g.: GANs)\n",
      "    def training_step(self, batch, batch_idx):\n",
      "        opt1, opt2 = self.optimizers()\n",
      "\n",
      "        # do training_step with encoder\n",
      "        ...\n",
      "        opt1.step()\n",
      "        # do training_step with decoder\n",
      "        ...\n",
      "        opt2.step()\n",
      "\n",
      "Note:\n",
      "    When ``accumulate_grad_batches`` > 1, the loss returned here will be automatically\n",
      "    normalized by ``accumulate_grad_batches`` internally.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "BaseLitModel.training_step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "BaseLitModel._run_on_batch??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizer(self: LinearRegression) -> torch.optim.Optimizer:\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "    return optimizer\n",
    "\n",
    "LinearRegression.configure_optimizers = configure_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one.\n",
      "But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in\n",
      "the manual optimization mode.\n",
      "\n",
      "Return:\n",
      "    Any of these 6 options.\n",
      "\n",
      "    - **Single optimizer**.\n",
      "    - **List or Tuple** of optimizers.\n",
      "    - **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers\n",
      "      (or multiple ``lr_scheduler_config``).\n",
      "    - **Dictionary**, with an ``\"optimizer\"`` key, and (optionally) a ``\"lr_scheduler\"``\n",
      "      key whose value is a single LR scheduler or ``lr_scheduler_config``.\n",
      "    - **None** - Fit will run without any optimizer.\n",
      "\n",
      "The ``lr_scheduler_config`` is a dictionary which contains the scheduler and its associated configuration.\n",
      "The default configuration is shown below.\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    lr_scheduler_config = {\n",
      "        # REQUIRED: The scheduler instance\n",
      "        \"scheduler\": lr_scheduler,\n",
      "        # The unit of the scheduler's step size, could also be 'step'.\n",
      "        # 'epoch' updates the scheduler on epoch end whereas 'step'\n",
      "        # updates it after a optimizer update.\n",
      "        \"interval\": \"epoch\",\n",
      "        # How many epochs/steps should pass between calls to\n",
      "        # `scheduler.step()`. 1 corresponds to updating the learning\n",
      "        # rate after every epoch/step.\n",
      "        \"frequency\": 1,\n",
      "        # Metric to to monitor for schedulers like `ReduceLROnPlateau`\n",
      "        \"monitor\": \"val_loss\",\n",
      "        # If set to `True`, will enforce that the value specified 'monitor'\n",
      "        # is available when the scheduler is updated, thus stopping\n",
      "        # training if not found. If set to `False`, it will only produce a warning\n",
      "        \"strict\": True,\n",
      "        # If using the `LearningRateMonitor` callback to monitor the\n",
      "        # learning rate progress, this keyword can be used to specify\n",
      "        # a custom logged name\n",
      "        \"name\": None,\n",
      "    }\n",
      "\n",
      "When there are schedulers in which the ``.step()`` method is conditioned on a value, such as the\n",
      ":class:`torch.optim.lr_scheduler.ReduceLROnPlateau` scheduler, Lightning requires that the\n",
      "``lr_scheduler_config`` contains the keyword ``\"monitor\"`` set to the metric name that the scheduler\n",
      "should be conditioned on.\n",
      "\n",
      ".. testcode::\n",
      "\n",
      "    # The ReduceLROnPlateau scheduler requires a monitor\n",
      "    def configure_optimizers(self):\n",
      "        optimizer = Adam(...)\n",
      "        return {\n",
      "            \"optimizer\": optimizer,\n",
      "            \"lr_scheduler\": {\n",
      "                \"scheduler\": ReduceLROnPlateau(optimizer, ...),\n",
      "                \"monitor\": \"metric_to_track\",\n",
      "                \"frequency\": \"indicates how often the metric is updated\"\n",
      "                # If \"monitor\" references validation metrics, then \"frequency\" should be set to a\n",
      "                # multiple of \"trainer.check_val_every_n_epoch\".\n",
      "            },\n",
      "        }\n",
      "\n",
      "\n",
      "    # In the case of two optimizers, only one using the ReduceLROnPlateau scheduler\n",
      "    def configure_optimizers(self):\n",
      "        optimizer1 = Adam(...)\n",
      "        optimizer2 = SGD(...)\n",
      "        scheduler1 = ReduceLROnPlateau(optimizer1, ...)\n",
      "        scheduler2 = LambdaLR(optimizer2, ...)\n",
      "        return (\n",
      "            {\n",
      "                \"optimizer\": optimizer1,\n",
      "                \"lr_scheduler\": {\n",
      "                    \"scheduler\": scheduler1,\n",
      "                    \"monitor\": \"metric_to_track\",\n",
      "                },\n",
      "            },\n",
      "            {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\n",
      "        )\n",
      "\n",
      "Metrics can be made available to monitor by simply logging it using\n",
      "``self.log('metric_to_track', metric_val)`` in your :class:`~pytorch_lightning.core.LightningModule`.\n",
      "\n",
      "Note:\n",
      "    Some things to know:\n",
      "\n",
      "    - Lightning calls ``.backward()`` and ``.step()`` automatically in case of automatic optimization.\n",
      "    - If a learning rate scheduler is specified in ``configure_optimizers()`` with key\n",
      "      ``\"interval\"`` (default \"epoch\") in the scheduler configuration, Lightning will call\n",
      "      the scheduler's ``.step()`` method automatically in case of automatic optimization.\n",
      "    - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizer.\n",
      "    - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you.\n",
      "    - If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them\n",
      "      yourself.\n",
      "    - If you need to control how often the optimizer steps, override the :meth:`optimizer_step` hook.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneCycleLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_total_steps\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lr_scheduler\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"monitor\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"validation/loss\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "BaseLitModel.configure_optimizers??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=20, accelerator='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelatedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, N=10_000):\n",
    "        self.N = N\n",
    "        self.xs = torch.randn(size=(N, 1))\n",
    "        self.ys = torch.randn_like(self.xs) + self.xs  # correlated target data: y ~ N(x, 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.xs[idx], self.ys[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "\n",
    "dataset = CorrelatedDataset()\n",
    "tdl = torch.utils.data.DataLoader(dataset, batch_size=32, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_xs, example_ys = next(iter(tdl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs:\n",
      "tensor([[-0.2429],\n",
      "        [-0.9342],\n",
      "        [-0.2483],\n",
      "        [-1.2082],\n",
      "        [-0.4777],\n",
      "        [ 0.5201],\n",
      "        [ 1.6423],\n",
      "        [-0.1596],\n",
      "        [ 2.3228],\n",
      "        [-0.9634]])\n",
      "ys:\n",
      "tensor([[ 0.3856],\n",
      "        [ 0.0418],\n",
      "        [-1.5879],\n",
      "        [-1.6987],\n",
      "        [ 1.5918],\n",
      "        [ 1.1458],\n",
      "        [ 2.8387],\n",
      "        [-0.7786],\n",
      "        [ 3.4444],\n",
      "        [-1.8255]])\n"
     ]
    }
   ],
   "source": [
    "print(\"xs:\", example_xs[:10], sep=\"\\n\")\n",
    "print(\"ys:\", example_ys[:10], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGwCAYAAABRgJRuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAij0lEQVR4nO3df2zV5d3/8dehg2KBc1w5pyCjlGIbFuMPGrQMunR0N1Mxc/LHyNJkWkhDDIESxCyDLdO4xXWL3o6kI+gSB2JG1enUhMwZRKAb/kAZNeg9SGspsFbwHBrOoadbS9rz/WPfNpyuPT1tz/lc53Od5yM5ib3OKX3LQc7L63pf1+WJxWIxAQAAuNwU0wUAAACkAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKXzFdgJMGBgbU2dmpWbNmyePxmC4HAAAkIRaL6erVq5o3b56mTBl9PiarQk1nZ6cKCwtNlwEAACbgwoULmj9//qjPZ1WomTVrlqT//KZ4vV7D1QAAgGREIhEVFhYOfY6PJqtCzeCSk9frJdQAAOAyY7WO0CgMAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFbIqmsSAACwWVuwW+e6erRw9gwV+2eYLsdxhBoAAFzuSk+ftjQ2q6klODRWWRpQQ3WZfHlTHakhEwIVoQYAAJfb0tisY62huLFjrSHVNZ7UvtrytP7sTAhUg+ipAQDAxdqC3WpqCao/Fosb74/F1NQS1NlQNK0/P1GgchqhBgAAFzvX1ZPw+fbL6Qs1pgPVcIQaAABcrCg/L+HzC2enr7/FZKAaCaEGAAAXWxSYqcrSgHI8nrjxHI9HlaWBtDbtmgxUIyHUAADgcg3VZaoo8ceNVZT41VBdltafazJQjcQTiw1bCLNYJBKRz+dTOByW1+s1XQ4AACl1NhRV++Woo9uqwz3XVNd4Mq27n5L9/CbUAACASUtnoEr285tzagAAwKQV+82fYkxPDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVXBNqdu/erdtvv11er1der1fLly/XW2+9ZbosAACQIVwTaubPn69f/epXOnHihD7++GN9+9vf1gMPPKDPPvvMdGkAACADeGKxWMx0EROVn5+vp556SrW1tSM+39vbq97e3qGvI5GICgsLFQ6H5fV6nSoTAABMQiQSkc/nG/Pz2zUzNdfr7+/XSy+9pGg0quXLl4/6uvr6evl8vqFHYWGhg1UCAAAnuWqm5tSpU1q+fLn+/e9/a+bMmdq/f7/uu+++UV/PTA0AAO6X7EzNVxysadIWL16s5uZmhcNhvfrqq6qpqdHRo0d1yy23jPj63Nxc5ebmOlwlAAAwwVUzNcOtWrVKN998s5577rmkXp9s0gMAAJnD6p6aQQMDA3HLSwAAIHu5Zvlpx44dWr16tRYsWKCrV69q//79OnLkiN5++23TpQEAslhbsFvnunq0cPYMFftnmC4nq7km1Hz55Zd66KGH9MUXX8jn8+n222/X22+/re985zumSwMAZKErPX3a0tisppbg0FhlaUAN1WXy5U01WFn2cnVPzXjRUwMASJWHnj+uY60h9V/3MZrj8aiixK99teUGK7NPVvTUAABgQluwW00twbhAI0n9sZiaWoI6G4oaqiy7EWoAABinc109CZ9vv0yoMYFQAwDAOBXl5yV8fuFsGoZNINQAADBOiwIzVVkaUI7HEzee4/GosjTALihDCDUAAExAQ3WZKkr8cWMVJX41VJcZqgiu2dINAEAm8eVN1b7acp0NRdV+Oco5NRmAUAMAwCQU+wkzmYLlJwAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwgmtCTX19ve666y7NmjVLBQUFWrNmjc6cOWO6LAAAkCFcE2qOHj2qTZs26YMPPtDBgwd17do13X333YpGo6ZLAwAAGcATi8VipouYiGAwqIKCAh09elSVlZVJfU8kEpHP51M4HJbX601zhQAAIBWS/fz+ioM1pVQ4HJYk5efnj/qa3t5e9fb2Dn0diUTSXhcAADDDNctP1xsYGNDWrVtVUVGhW2+9ddTX1dfXy+fzDT0KCwsdrBIAADjJlctPGzdu1FtvvaW//e1vmj9//qivG2mmprCwkOUnAABcxNrlp82bN+vAgQNqampKGGgkKTc3V7m5uQ5VBgAATHJNqInFYqqrq9Prr7+uI0eOqLi42HRJALJEW7Bb57p6tHD2DBX7Z5guB8AoXBNqNm3apP379+vNN9/UrFmzdPHiRUmSz+fTDTfcYLg6ADa60tOnLY3NamoJDo1VlgbUUF0mX95Ug5UBGIlremo8Hs+I43v27NG6deuS+jXY0g1gPB56/riOtYbUf91fkzkejypK/NpXW26wMiC7WNdT45LsBcASbcHuuBmaQf2xmJpagjobirIUBWQYV27pBoB0O9fVk/D59sucZn69tmC3Dp/5UmdD/L7AHNfM1ACAk4ry8xI+v3A2szQSfUfILMzUAMAIFgVmqrI0oJxh/Xw5Ho8qSwMsPf1/Wxqbdaw1FDd2rDWkusaThipCNiPUAMAoGqrLVFHijxurKPGrobrMUEWZZbDvqH9Yz+P1fUeAk1h+AoBR+PKmal9tuc6Gomq/HOWcmmGS6Tvi9wtOItQAwBiK/YSZkdB3hEzD8hNgIXaiwAn0HSHTMFMDWISdKHBaQ3WZ6hpPxv2Zc6LviKsrMBLXnCicCpwoDNtxAi5McarviOCenZL9/Gb5CbAEO1FgUrF/hqoWF6R91oQt5EiEUANYIhUn4NKLg0xGcMdY6KkBLDGZnShM6cMN2EKOsTBTA1hiMjtRmNKHG7CFHGMh1AAWmcgJuEzpwy3YQo6xsPwEWGQiJ+AypQ83MbWFHO5AqAEsNJ4TcJnSh5twdQUSIdQAWW5wSn+08234wEAm4uoKjISeGgDcRg3ACszUAGBKH4AVCDUAhjClD8DNWH4CAABWINQAAAArEGoAAIAVCDUAAMAKNAoDAFypLditc1097NbDEEINAMBVuFUeo2H5CQDgKtwqj9EQagAArsGt8kiEUAMAWawt2K3DZ750TRhI5lZ5ZC96agAgC7m1L4Vb5ZEIMzUAkIXc2pcyeKt8jscTN57j8aiyNMAuqCxHqAGALOP2vhRulcdoWH4CgCyTTF9KJs94cKs8RkOoAYAM4sSBcrb0pXCrPIYj1ABABnCycXewL+VYayhuCSrH41FFiZ+gANeipwYAMoDTjbv0pcBGzNQAgGGDjbvDXd+4m+rZE/pSYCNCDQAYZrJxl74U2ITlJwAwzJbGXcA0Qg0AGMaBckBqEGoAIAPQuAtMHj01AJABaNwFJs9VMzVNTU26//77NW/ePHk8Hr3xxhumSwKAlCr2z1DV4gICDTABrgo10WhUd9xxh3bt2mW6FAAAkGFctfy0evVqrV69OunX9/b2qre3d+jrSCSSjrIAAEAGcNVMzXjV19fL5/MNPQoLC02XBAAA0sTqULNjxw6Fw+Ghx4ULF0yXBAAA0sRVy0/jlZubq9zcXNNlAAAAB1g9UwMAALIHoQYAAFjBVctP3d3dam1tHfr67Nmzam5uVn5+vhYsWGCwMgAAYJqrQs3HH3+sqqqqoa+3bdsmSaqpqdHevXsNVQUAADKBq0LNypUrFYvFTJcBACnRFuzWua4erkQAUsRVoQZAdrMlBFzp6dOWxmY1tQSHxipLA2qoLpMvb6rBygB3I9QAyHi2hYAtjc061hqKGzvWGlJd40ntqy03VBXgfux+ApDxEoUAt2kLdqupJaj+YUvp/bGYmlqCOhuKGqoMcD9CDYCMZlsIONfVk/D59svu+vcBMgmhBkBGsy0EFOXnJXx+4Wz39goBphFqAGQ020LAosBMVZYGlOPxxI3neDyqLA24ugEaMI1QAyCj2RgCGqrLVFHijxurKPGrobrMUEWAHTyxLDr4JRKJyOfzKRwOy+v1mi4HQJLCPddU13jSmt1Pg86Gomq/HHX9FnUg3ZL9/CbUAHANQgCQnZL9/OacGgCuUewnzAAYHT01AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFrkkA4Ii2YLfOdfVwbxOAtCHUAEirKz192tLYbN0N2wAyD8tPANJqS2OzjrWG4saOtYZU13jSUEUAbEWoAZA2bcFuNbUE1R+LxY33x2JqagnqbChqqDIANiLUAEibc109CZ9vv0yoAZA6hBoAaVOUn5fw+YWzaRgGkDqEGgBpsygwU5WlAeV4PHHjOR6PKksD7IICkFKEGgBp1VBdpooSf9xYRYlfDdVlhioCYCu2dANIK1/eVO2rLdfZUFTtl6OcUwMgbcY9U1NTU6OmpqZ01AIgDdqC3Tp85kvjO42K/TNUtbiAQAMgbcY9UxMOh7Vq1SoVFRVp/fr1qqmp0de+9rV01AZgEjj0DkC2GfdMzRtvvKGOjg5t3LhRL7/8shYuXKjVq1fr1Vdf1bVr19JRI4AJ4NA7ANlmQo3CgUBA27Zt0yeffKIPP/xQJSUlevDBBzVv3jw98sgjamlpSXWdAMaBQ+8AZKNJ7X764osvdPDgQR08eFA5OTm67777dOrUKd1yyy36zW9+k6oaAYwTh94ByEbjDjXXrl3Ta6+9pu9+97sqKirSH//4R23dulWdnZ164YUX9M477+iVV17Rz3/+83TUCyAJHHoHIBuNu1H4pptu0sDAgKqrq3X8+HEtWbLkv15TVVWlG2+8MQXlAZiIwUPvjrWG4pagcjweVZT42YEEwEqeWGzYovsYXnzxRa1du1bTp09PV01pE4lE5PP5FA6H5fV6TZcDpFW455rqGk+y+wmA6yX7+T3uUONmhBpkIw69A+B2yX5+c6IwkEZtwW6d6+oxGiiK/YQZANmBUAOkAQffAYDzuNASSAMOvgMA57ku1OzatUsLFy7U9OnTtWzZMh0/ftx0SUCcZA6+y5T7mADAJq5afnr55Ze1bds2Pfvss1q2bJl27type+65R2fOnFFBQYHp8gBJYx98V9f4d33aERn6mmUpAEgNV83UPPPMM9qwYYPWr1+vW265Rc8++6zy8vL0+9//3nRpwJCxDr77v85I3NcsSwFAargm1PT19enEiRNatWrV0NiUKVO0atUqvf/++yN+T29vryKRSNwDSLfBg+9yPJ648cH/2AaGHaLAfUwAkBquCTWhUEj9/f2aM2dO3PicOXN08eLFEb+nvr5ePp9v6FFYWOhEqYAaqstUUeKPG7tlXuKzkbiPCQAmx1U9NeO1Y8cObdu2bejrSCRCsIEjfHlTta+2PO7gu1gspm//79FRv4f7mABgclwTavx+v3JycnTp0qW48UuXLmnu3Lkjfk9ubq5yc3OdKA8Y0fCD77iPCXCnTDhIE2NzzfLTtGnTtHTpUh06dGhobGBgQIcOHdLy5csNVgYkb6RlqYoSvxqqywxVBCCRKz19euj54/r2/x7V+j0fqerpI3ro+eMK91wzXRpG4JqZGknatm2bampqdOedd6q8vFw7d+5UNBrV+vXrTZcGJGWkZSn+rw/IXIkO0txXW26oKozGVaHmBz/4gYLBoB577DFdvHhRS5Ys0V/+8pf/ah4GMh33MQGZb/AgzeGu37HIf8eZxVWhRpI2b96szZs3my4DAGC5sQ7SbL9MqMk0rumpAQDASWMdpMmOxcxDqAGQFbhvC+M12kGaOR6PKksDzNJkINctPwHAeFzp6dOWxua43gju20KyGqrLVNd4Mu7PDzsWM5cnFht2lbDFIpGIfD6fwuGwvN7Ep7sCsMNDzx8f9Wwgdq8gWexYNCvZz29magBYi90rSBV2LLoDPTUArJXM7hUA9iDUALAWu1eA7EKoAWAtdq8A2YVQA8Bq3LcFZA8ahQFYjfu2gOxBqAGQFdi9AtiP5ScAAGAFQg0AALACy08AHNUW7Na5rh56WwCkHKEGgCO4gwlAurH8BMARWxqbdaw1FDd2rDWkusaThioCYBtCDYC0G7yDqX/Y/bnX38EEAJNFqAGQdtzBBMAJhBoAaccdTACcQKgBkHbcwQTACYQaAI7gDiYA6caWbgCO4A4mAOlGqAHgKO5gApAuLD8BAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBLd0AMkJbsFvnuno4vwbAhBFqABh1padPWxqb1dQSHBqrLA2oobpMvrypBisD4DYsPwEwaktjs461huLGjrWGVNd40lBFANyKUAPAmLZgt5paguqPxeLG+2MxNbUEdTYUNVQZADci1AAw5lxXT8Ln2y8TagAkj1ADwJii/LyEzy+cTcMwgOQRagAYsygwU5WlAeV4PHHjOR6PKksD7IICMC6EGgBGNVSXqaLEHzdWUeJXQ3WZoYoAuBVbugEY5cubqn215Tobiqr9cpRzagBMGKEGQEYo9hNmAEwOoQZIM07KBQBnEGqANOGkXABwlmsahZ988kmtWLFCeXl5uvHGG02XA4yJk3IBwFmuCTV9fX1au3atNm7caLoUYEyclAsAznPN8tMTTzwhSdq7d6/ZQoAkJHNSLv01AJBargk1E9Hb26ve3t6hryORiMFqkE04KTf70BAOmGd1qKmvrx+a4QGcNHhS7rHWUNwSVI7Ho4oSPx96FqEhHMgcRntqtm/fLo/Hk/Bx+vTpCf/6O3bsUDgcHnpcuHAhhdUDiXFSbnagIRzIHEZnah599FGtW7cu4WsWLVo04V8/NzdXubm5E/5+YDI4Kdd+gw3hw13fEM57DjjHaKgJBAIKBAImSwDSjpNy7UVDOJBZXNNTc/78eXV1den8+fPq7+9Xc3OzJKmkpEQzZ840WxyArERDOJBZXBNqHnvsMb3wwgtDX5eV/acv4fDhw1q5cqWhqgBkMxrCgcziicWGnQ5msUgkIp/Pp3A4LK/Xa7ocABYI91xTXeNJdj8BaZTs57drZmoAIBPREA5kDkINAKQADeGAea65+wkAACARQg0AALACoQYAAFiBUAMAAKxAozCQAbjhGQAmj1ADjMKJoMENzwCQOoQaYBgng0aiG5731Zan9GcBgO3oqQGGSRQ0Umnwhuf+YYd6X3/DMwAgeYQa4DpOBo1kbngGACSPUANcx8mgwQ3PAJBahBrgOk4GjcEbnnM8nrjxHI9HlaUBdkEBwDgRaoDrOB00GqrLVFHijxurKPGrobospT8HALKBJxYb1jxgsWSvLkd2C/dcU13jSUe3WXPDMwCMLtnPb0INMAqCBgBkhmQ/vzmnBhhFsZ8wAwBuQqiBq3CdAABgNIQauALXCQAAxsLuJ7iCU6f8AgDci1CDjMd1Au7XFuzW4TNf8l4BSCuWn5Dxkjnll/6azMSyIQAnMVODjMd1Au7FsiEAJxFqkPG4TsCdWDYE4DRCDVyB6wTch1vIATiNnhq4gi9vqvbVlnPKr4uwbAjAaYQauEoqTvnlAD9nDC4bHmsNxS1B5Xg8qijx83sPIOUINcga7MRxXkN12X9dDsqyIYB04UJLZI2Hnj8+6qzBvtpyg5XZj2VDAJPBhZbAdQZ34gx3/U4cPmzTh8tBATiB3U/ICuzEAQD7EWqQFdiJAwD2I9QgKzh5gB/3HAGAGfTUIGukeycOu6sAwCx2PyHrpGsnjtt3V3F+D4BMxe4nYBTp2Inj5t1VzDABsAU9NUAKuHl3FTdpA7AFoQZIAbfuruImbQA2IdQAKeDk7qpUcvMMEwAMR6gBUqShukwVJf64sUy/58itM0wAMBIahYEU8eVN1b7aclfdc8RN2gBswkwNkGLF/hmqWlzgmkDgxhkmABiJK2Zq2tvb9Ytf/ELvvvuuLl68qHnz5umHP/yhfvrTn2ratGmmywNczY0zTAAwEleEmtOnT2tgYEDPPfecSkpK9Omnn2rDhg2KRqN6+umnTZcHWIGbtAG4nWtPFH7qqae0e/dutbW1jfqa3t5e9fb2Dn0diURUWFjIicIAALhIsicKu7anJhwOKz8/P+Fr6uvr5fP5hh6FhYUOVQcAAJzmylDT2tqqhoYGPfzwwwlft2PHDoXD4aHHhQsXHKoQAAA4zWio2b59uzweT8LH6dOn476no6ND9957r9auXasNGzYk/PVzc3Pl9XrjHgAAwE5Ge2qCwaAuX76c8DWLFi0a2uHU2dmplStX6hvf+Ib27t2rKVPGl8m4pRsAAPdxxS3dgUBAgUAgqdd2dHSoqqpKS5cu1Z49e8YdaAAAgN1csaW7o6NDK1euVFFRkZ5++mkFg8Gh5+bOnWuwMgAAkClcEWoOHjyo1tZWtba2av78+XHPuXRHOgAASDFXrOGsW7dOsVhsxAcAAIDkklADAAAwFkINAACwAqEGAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsAKhBgAAWIFQAwAArECoAQAAViDUAAAAKxBqAACAFQg1AADACoQaAABgBUINAACwAqEGAABYgVADAACsQKgBAABW+IrpAmzQFuzWua4eLZw9Q8X+GabLAQAgKxFqJuFKT5+2NDarqSU4NFZZGlBDdZl8eVMNVgYAQPZh+WkStjQ261hrKG7sWGtIdY0nDVUEAED2ItRMUFuwW00tQfXHYnHj/bGYmlqCOhuKGqoMAIDsRKiZoHNdPQmfb79MqAEAwEmEmgkqys9L+PzC2TQMAwDgJELNBC0KzFRlaUA5Hk/ceI7Ho8rSALugAABwGKFmEhqqy1RR4o8bqyjxq6G6zFBFAABkL7Z0T4Ivb6r21ZbrbCiq9stRzqkBAMAgQk0KFPsJM8ngkEIAQDoRapB2HFIIAHACPTVIOw4pBAA4wTWh5nvf+54WLFig6dOn66abbtKDDz6ozs5O02VhDBxSCABwimtCTVVVlV555RWdOXNGr732mj7//HN9//vfN10WxsAhhQAAp7imp+aRRx4Z+ueioiJt375da9as0bVr1zR1Kn0ZmYpDCgEATnHNTM31urq69Ic//EErVqxIGGh6e3sViUTiHnAWhxQCAJziqlDz4x//WDNmzNDs2bN1/vx5vfnmmwlfX19fL5/PN/QoLCx0qFJcj0MKAQBO8MRiwzo4HbR9+3b9+te/Tviaf/zjH/r6178uSQqFQurq6tK5c+f0xBNPyOfz6cCBA/IMmwUY1Nvbq97e3qGvI5GICgsLFQ6H5fV6U/cvgqRwSCEAYCIikYh8Pt+Yn99GQ00wGNTly5cTvmbRokWaNm3af43/85//VGFhod577z0tX748qZ+X7G8KAADIHMl+fhttFA4EAgoEAhP63oGBAUmKm4kBAADZyxW7nz788EN99NFH+uY3v6mvfvWr+vzzz/Wzn/1MN998c9KzNAAAwG6uaBTOy8vTn/70J/3P//yPFi9erNraWt1+++06evSocnNzTZcHAAAygCtmam677Ta9++67pssAAAAZzBUzNQAAAGMh1AAAACsQagAAgBUINQAAwAqEGgAAYAVCDQAAsIIrtnSnyuCNENzWDQCAewx+bo91s1NWhZqrV69KErd1AwDgQlevXpXP5xv1eaMXWjptYGBAnZ2dmjVr1qg3e7vN4M3jFy5c4JJOQ3gPzOM9yAy8D+bZ+h7EYjFdvXpV8+bN05Qpo3fOZNVMzZQpUzR//nzTZaSF1+u16g+wG/EemMd7kBl4H8yz8T1INEMziEZhAABgBUINAACwAqHG5XJzc/X4449zW7lBvAfm8R5kBt4H87L9PciqRmEAAGAvZmoAAIAVCDUAAMAKhBoAAGAFQg0AALACocYS7e3tqq2tVXFxsW644QbdfPPNevzxx9XX12e6tKzz5JNPasWKFcrLy9ONN95oupyssGvXLi1cuFDTp0/XsmXLdPz4cdMlZZWmpibdf//9mjdvnjwej9544w3TJWWV+vp63XXXXZo1a5YKCgq0Zs0anTlzxnRZRhBqLHH69GkNDAzoueee02effabf/OY3evbZZ/WTn/zEdGlZp6+vT2vXrtXGjRtNl5IVXn75ZW3btk2PP/64/v73v+uOO+7QPffcoy+//NJ0aVkjGo3qjjvu0K5du0yXkpWOHj2qTZs26YMPPtDBgwd17do13X333YpGo6ZLcxxbui321FNPaffu3WprazNdSlbau3evtm7dqitXrpguxWrLli3TXXfdpd/+9reS/nPHW2Fhoerq6rR9+3bD1WUfj8ej119/XWvWrDFdStYKBoMqKCjQ0aNHVVlZabocRzFTY7FwOKz8/HzTZQBp09fXpxMnTmjVqlVDY1OmTNGqVav0/vvvG6wMMCccDktSVv79T6ixVGtrqxoaGvTwww+bLgVIm1AopP7+fs2ZMydufM6cObp48aKhqgBzBgYGtHXrVlVUVOjWW281XY7jCDUZbvv27fJ4PAkfp0+fjvuejo4O3XvvvVq7dq02bNhgqHK7TOR9AACnbdq0SZ9++qleeukl06UY8RXTBSCxRx99VOvWrUv4mkWLFg39c2dnp6qqqrRixQr97ne/S3N12WO87wOc4ff7lZOTo0uXLsWNX7p0SXPnzjVUFWDG5s2bdeDAATU1NWn+/PmmyzGCUJPhAoGAAoFAUq/t6OhQVVWVli5dqj179mjKFCbiUmU87wOcM23aNC1dulSHDh0aakwdGBjQoUOHtHnzZrPFAQ6JxWKqq6vT66+/riNHjqi4uNh0ScYQaizR0dGhlStXqqioSE8//bSCweDQc/wfq7POnz+vrq4unT9/Xv39/WpubpYklZSUaObMmWaLs9C2bdtUU1OjO++8U+Xl5dq5c6ei0ajWr19vurSs0d3drdbW1qGvz549q+bmZuXn52vBggUGK8sOmzZt0v79+/Xmm29q1qxZQ/1kPp9PN9xwg+HqHBaDFfbs2ROTNOIDzqqpqRnxfTh8+LDp0qzV0NAQW7BgQWzatGmx8vLy2AcffGC6pKxy+PDhEf/M19TUmC4tK4z2d/+ePXtMl+Y4zqkBAABWoOkCAABYgVADAACsQKgBAABWINQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1ABwrWAwqLlz5+qXv/zl0Nh7772nadOm6dChQwYrA2ACF1oCcLU///nPWrNmjd577z0tXrxYS5Ys0QMPPKBnnnnGdGkAHEaoAeB6mzZt0jvvvKM777xTp06d0kcffaTc3FzTZQFwGKEGgOv961//0q233qoLFy7oxIkTuu2220yXBMAAemoAuN7nn3+uzs5ODQwMqL293XQ5AAxhpgaAq/X19am8vFxLlizR4sWLtXPnTp06dUoFBQWmSwPgMEINAFf70Y9+pFdffVWffPKJZs6cqW9961vy+Xw6cOCA6dIAOIzlJwCudeTIEe3cuVMvvviivF6vpkyZohdffFF//etftXv3btPlAXAYMzUAAMAKzNQAAAArEGoAAIAVCDUAAMAKhBoAAGAFQg0AALACoQYAAFiBUAMAAKxAqAEAAFYg1AAAACsQagAAgBUINQAAwAr/D/xlYZB4xJnfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(data={\"x\": example_xs.flatten(), \"y\": example_ys.flatten()})\\\n",
    "  .plot(x=\"x\", y=\"y\", kind=\"scatter\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/miniconda3/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:634: Checkpoint directory /home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lightning_logs/version_5/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 2     \n",
      "---------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before trianing: 3.4017789363861084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after training 3.4017789363861084\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "print(f\"Loss before trianing: {torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item()}\")\n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=tdl)\n",
    "\n",
    "print(f\"Loss after training {torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.DataFrame(data={\"x\": example_xs.flatten(), \"y\": example_ys.flatten()})\\\n",
    "  .plot(x=\"x\", y=\"y\", legend=True, kind=\"scatter\", label=\"data\")\n",
    "\n",
    "inps = torch.arange(-2, 2, 0.5)[:, None]\n",
    "ax.plot(inps, model(inps).detach(), lw=2, color=\"k\", label=\"predictions\"); ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Customize every aspect of training via flags.'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Trainer.__init__.__doc__.strip().split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customize every aspect of training via flags.\n",
      "\n",
      "        Args:\n",
      "            accelerator: Supports passing different accelerator types (\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"mps\", \"auto\")\n",
      "                as well as custom accelerator instances.\n",
      "\n",
      "            strategy: Supports different training strategies with aliases as well custom strategies.\n",
      "                Default: ``\"auto\"``.\n",
      "\n",
      "            devices: The devices to use. Can be set to a positive number (int or str), a sequence of device indices\n",
      "                (list or str), the value ``-1`` to indicate all available devices should be used, or ``\"auto\"`` for\n",
      "                automatic selection based on the chosen accelerator. Default: ``\"auto\"``.\n",
      "\n",
      "            num_nodes: Number of GPU nodes for distributed training.\n",
      "                Default: ``1``.\n",
      "\n",
      "            precision: Double precision (64, '64' or '64-true'), full precision (32, '32' or '32-true'),\n",
      "                16bit mixed precision (16, '16', '16-mixed') or bfloat16 mixed precision ('bf16', 'bf16-mixed').\n",
      "                Can be used on CPU, GPU, TPUs, HPUs or IPUs.\n",
      "                Default: ``'32-true'``.\n",
      "\n",
      "            logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\n",
      "                the default ``TensorBoardLogger`` if it is installed, otherwise ``CSVLogger``.\n",
      "                ``False`` will disable logging. If multiple loggers are provided, local files\n",
      "                (checkpoints, profiler traces, etc.) are saved in the ``log_dir`` of the first logger.\n",
      "                Default: ``True``.\n",
      "\n",
      "            callbacks: Add a callback or list of callbacks.\n",
      "                Default: ``None``.\n",
      "\n",
      "            fast_dev_run: Runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\n",
      "                of train, val and test to find any bugs (ie: a sort of unit test).\n",
      "                Default: ``False``.\n",
      "\n",
      "            max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\n",
      "                If both max_epochs and max_steps are not specified, defaults to ``max_epochs = 1000``.\n",
      "                To enable infinite training, set ``max_epochs = -1``.\n",
      "\n",
      "            min_epochs: Force training for at least these many epochs. Disabled by default (None).\n",
      "\n",
      "            max_steps: Stop training after this number of steps. Disabled by default (-1). If ``max_steps = -1``\n",
      "                and ``max_epochs = None``, will default to ``max_epochs = 1000``. To enable infinite training, set\n",
      "                ``max_epochs`` to ``-1``.\n",
      "\n",
      "            min_steps: Force training for at least these number of steps. Disabled by default (``None``).\n",
      "\n",
      "            max_time: Stop training after this amount of time has passed. Disabled by default (``None``).\n",
      "                The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\n",
      "                :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\n",
      "                :class:`datetime.timedelta`.\n",
      "\n",
      "            limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            overfit_batches: Overfit a fraction of training/validation data (float) or a set number of batches (int).\n",
      "                Default: ``0.0``.\n",
      "\n",
      "            val_check_interval: How often to check the validation set. Pass a ``float`` in the range [0.0, 1.0] to check\n",
      "                after a fraction of the training epoch. Pass an ``int`` to check after a fixed number of training\n",
      "                batches. An ``int`` value can only be higher than the number of training batches when\n",
      "                ``check_val_every_n_epoch=None``, which validates after every ``N`` training batches\n",
      "                across epochs or during iteration-based training.\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            check_val_every_n_epoch: Perform a validation loop every after every `N` training epochs. If ``None``,\n",
      "                validation will be done solely based on the number of training batches, requiring ``val_check_interval``\n",
      "                to be an integer value.\n",
      "                Default: ``1``.\n",
      "\n",
      "            num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\n",
      "                Set it to `-1` to run all batches in all validation dataloaders.\n",
      "                Default: ``2``.\n",
      "\n",
      "            log_every_n_steps: How often to log within steps.\n",
      "                Default: ``50``.\n",
      "\n",
      "            enable_checkpointing: If ``True``, enable checkpointing.\n",
      "                It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.callbacks`.\n",
      "                Default: ``True``.\n",
      "\n",
      "            enable_progress_bar: Whether to enable to progress bar by default.\n",
      "                Default: ``True``.\n",
      "\n",
      "            enable_model_summary: Whether to enable model summarization by default.\n",
      "                Default: ``True``.\n",
      "\n",
      "            accumulate_grad_batches: Accumulates gradients over k batches before stepping the optimizer.\n",
      "                Default: 1.\n",
      "\n",
      "            gradient_clip_val: The value at which to clip gradients. Passing ``gradient_clip_val=None`` disables\n",
      "                gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.\n",
      "                Default: ``None``.\n",
      "\n",
      "            gradient_clip_algorithm: The gradient clipping algorithm to use. Pass ``gradient_clip_algorithm=\"value\"``\n",
      "                to clip by value, and ``gradient_clip_algorithm=\"norm\"`` to clip by norm. By default it will\n",
      "                be set to ``\"norm\"``.\n",
      "\n",
      "            deterministic: If ``True``, sets whether PyTorch operations must use deterministic algorithms.\n",
      "                Set to ``\"warn\"`` to use deterministic algorithms whenever possible, throwing warnings on operations\n",
      "                that don't support deterministic mode. If not set, defaults to ``False``. Default: ``None``.\n",
      "\n",
      "            benchmark: The value (``True`` or ``False``) to set ``torch.backends.cudnn.benchmark`` to.\n",
      "                The value for ``torch.backends.cudnn.benchmark`` set in the current session will be used\n",
      "                (``False`` if not manually set). If :paramref:`~lightning.pytorch.trainer.trainer.Trainer.deterministic`\n",
      "                is set to ``True``, this will default to ``False``. Override to manually set a different value.\n",
      "                Default: ``None``.\n",
      "\n",
      "            inference_mode: Whether to use :func:`torch.inference_mode` or :func:`torch.no_grad` during\n",
      "                evaluation (``validate``/``test``/``predict``).\n",
      "\n",
      "            use_distributed_sampler: Whether to wrap the DataLoader's sampler with\n",
      "                :class:`torch.utils.data.DistributedSampler`. If not specified this is toggled automatically for\n",
      "                strategies that require it. By default, it will add ``shuffle=True`` for the train sampler and\n",
      "                ``shuffle=False`` for validation/test/predict samplers. If you want to disable this logic, you can pass\n",
      "                ``False`` and add your own distributed sampler in the dataloader hooks. If ``True`` and a distributed\n",
      "                sampler was already added, Lightning will not replace the existing one. For iterable-style datasets,\n",
      "                we don't do this automatically.\n",
      "\n",
      "            profiler: To profile individual steps during training and assist in identifying bottlenecks.\n",
      "                Default: ``None``.\n",
      "\n",
      "            detect_anomaly: Enable anomaly detection for the autograd engine.\n",
      "                Default: ``False``.\n",
      "\n",
      "            barebones: Whether to run in \"barebones mode\", where all features that may impact raw speed are\n",
      "                disabled. This is meant for analyzing the Trainer overhead and is discouraged during regular training\n",
      "                runs. The following features are deactivated:\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_checkpointing`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.logger`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_progress_bar`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.log_every_n_steps`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_model_summary`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.num_sanity_val_steps`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.fast_dev_run`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.detect_anomaly`,\n",
      "                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.profiler`,\n",
      "                :meth:`~lightning.pytorch.core.LightningModule.log`,\n",
      "                :meth:`~lightning.pytorch.core.LightningModule.log_dict`.\n",
      "            plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\n",
      "                Default: ``None``.\n",
      "\n",
      "            sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\n",
      "                Default: ``False``.\n",
      "\n",
      "            reload_dataloaders_every_n_epochs: Set to a positive integer to reload dataloaders every n epochs.\n",
      "                Default: ``0``.\n",
      "\n",
      "            default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\n",
      "                Default: ``os.getcwd()``.\n",
      "                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n",
      "\n",
      "        Raises:\n",
      "            TypeError:\n",
      "                If ``gradient_clip_val`` is not an int or float.\n",
      "\n",
      "            MisconfigurationException:\n",
      "                If ``gradient_clip_algorithm`` is invalid.\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(pl.Trainer.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.py  __init__.py  __pycache__\n"
     ]
    }
   ],
   "source": [
    "!ls text_recognizer/lit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  __pycache__  run_experiment.py  util.py\n"
     ]
    }
   ],
   "source": [
    "!ls training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment-running framework. \n",
      "    Run an experiment.\n",
      "\n",
      "    Sample command:\n",
      "    ```\n",
      "    python training/run_experiment.py --max_epochs=3 --gpus='0,' --num_workers=20 --model_class=MLP --data_class=MNIST\n",
      "    ```\n",
      "\n",
      "    For basic help documentation, run the command\n",
      "    ```\n",
      "    python training/run_experiment.py --help\n",
      "    ```\n",
      "\n",
      "    The available command line args differ depending on some of the arguments, including --model_class and --data_class.\n",
      "\n",
      "    To see which command line args are available and read their documentation, provide values for those arguments\n",
      "    before invoking --help, like so:\n",
      "    ```\n",
      "    python training/run_experiment.py --model_class=MLP --data_class=MNIST --help\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import training.run_experiment\n",
    "\n",
    "\n",
    "print(training.run_experiment.__doc__, training.run_experiment.main.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger)\n"
     ]
    }
   ],
   "source": [
    "# how the trainer is initialized in the training script\n",
    "!grep \"pl.Trainer.from\" training/run_experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/training/run_experiment.py\", line 10, in <module>\n",
      "    from text_recognizer import lit_models\n",
      "ModuleNotFoundError: No module named 'text_recognizer'\n"
     ]
    }
   ],
   "source": [
    "# displays the first few flags for controlling the Trainer from the command line\n",
    "!python training/run_experiment.py --help | grep \"pl.Trainer\" -A 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LightningModule` and the `Trainer` are the minimum amount you need\n",
    "to get started with PyTorch Lightning.\n",
    "\n",
    "But they aren't all you need.\n",
    "\n",
    "There are many more features built into Lightning and its ecosystem.\n",
    "\n",
    "We'll cover three more here:\n",
    "- `pl.LightningDataModule`s, for organizing dataloaders and handling data in distributed settings\n",
    "- `pl.Callback`s, for adding \"optional\" extra features to model training\n",
    "- `torchmetrics`, for efficiently computing and logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class CorrelatedDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, size=10_000, train_frac=0.8, batch_size=32):\n",
    "        super().__init__()  # again, mandatory superclass init, as with torch.nn.Modules\n",
    "\n",
    "        # set some constants, like the train/val split\n",
    "        self.size = size\n",
    "        self.train_frac, self.val_frac = train_frac, 1 - train_frac\n",
    "        self.train_indices = list(range(math.floor(self.size * train_frac)))\n",
    "        self.val_indices = list(range(self.train_indices[-1], self.size))\n",
    "\n",
    "        # under the hood, we've still got a torch Dataset\n",
    "        self.dataset = CorrelatedDataset(N=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(self, stage=None):  # prepares state that needs to be set for each GPU on each node\n",
    "    if stage == \"fit\" or stage is None:  # other stages: \"test\", \"predict\"\n",
    "        self.train_dataset = torch.utils.data.Subset(self.dataset, self.train_indices)\n",
    "        self.val_dataset = torch.utils.data.Subset(self.dataset, self.val_indices)\n",
    "\n",
    "def prepare_data(self):  # prepares state that needs to be set once per node\n",
    "    pass  # but we don't have any \"node-level\" computations\n",
    "\n",
    "\n",
    "CorrelatedDataModule.setup, CorrelatedDataModule.prepare_data = setup, prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataloader(self: pl.LightningDataModule) -> torch.utils.data.DataLoader:\n",
    "    return torch.utils.data.DataLoader(self.train_dataset, batch_size=32)\n",
    "\n",
    "def val_dataloader(self: pl.LightningDataModule) -> torch.utils.data.DataLoader:\n",
    "    return torch.utils.data.DataLoader(self.val_dataset, batch_size=32)\n",
    "\n",
    "CorrelatedDataModule.train_dataloader, CorrelatedDataModule.val_dataloader = train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before training: 3.3570358753204346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/stanley/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 2     \n",
      "---------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/home/stanley/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  13%|        | 32/250 [00:00<00:01, 145.43it/s, v_num=8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 250/250 [00:01<00:00, 151.24it/s, v_num=8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 250/250 [00:01<00:00, 150.73it/s, v_num=8]\n",
      "loss after training: 1.5875164270401\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "datamodule = CorrelatedDataModule()\n",
    "\n",
    "dataset = datamodule.dataset\n",
    "\n",
    "print(\"loss before training:\", torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item())\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator='gpu')\n",
    "trainer.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "print(\"loss after training:\", torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBaseDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mBaseDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningDataModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Base for all of our LightningDataModules.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Learn more at about LDMs at https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_workers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_NUM_WORKERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Make sure to set the variables below in subclasses\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mdata_dirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_DIRNAME\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0madd_to_argparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"--batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Number of examples to operate on per forward step. Default is {BATCH_SIZE}.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"--num_workers\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_NUM_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Number of additional processes to load data. Default is {DEFAULT_NUM_WORKERS}.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Return important settings of the dataset, which will be passed to instantiate models.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input_dims\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_dims\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Take the first steps to prepare data for use.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Use this method to do things that might write to disk or that need to be done only from a single GPU\u001b[0m\n",
      "\u001b[0;34m        in distributed settings (so don't set state `self.x = y`).\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Perform final setup to prepare data for consumption by DataLoader.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Here is where we typically split into train, validation, and test. This is done once per GPU in a DDP setting.\u001b[0m\n",
      "\u001b[0;34m        Should assign `torch Dataset` objects to self.data_train, self.data_val, and optionally self.data_test.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/text_recognizer/data/base_data_module.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     MNIST, EMNIST, EMNISTLines"
     ]
    }
   ],
   "source": [
    "from text_recognizer.data import BaseDataModule\n",
    "\n",
    "\n",
    "BaseDataModule??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseDataModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"MNIST DataModule.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOWNLOADED_DATA_DIRNAME\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNISTStem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDIMS\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIMS\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAPPING\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Download train and test MNIST data from PyTorch canonical source.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mTorchMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mTorchMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Split into train, val, test, and set dims.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmnist_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAL_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/text_recognizer/data/mnist.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "from text_recognizer.data.mnist import MNIST\n",
    "\n",
    "\n",
    "MNIST??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lightning' has no attribute 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stanley/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/lab2aself.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pl\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39m__all__  \u001b[39m# builtin Callbacks from Lightning\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lightning' has no attribute 'callbacks'"
     ]
    }
   ],
   "source": [
    "pl.callbacks.__all__  # builtin Callbacks from Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hooks:\n",
      "\ton_after_backward, on_before_backward, on_before_optimizer_step,\n",
      "\ton_before_zero_grad, on_exception, on_fit_end, on_fit_start, on_load_checkpoint,\n",
      "\ton_predict_batch_end, on_predict_batch_start, on_predict_end,\n",
      "\ton_predict_epoch_end, on_predict_epoch_start, on_predict_start,\n",
      "\ton_sanity_check_end, on_sanity_check_start, on_save_checkpoint,\n",
      "\ton_test_batch_end, on_test_batch_start, on_test_end, on_test_epoch_end,\n",
      "\ton_test_epoch_start, on_test_start, on_train_batch_end, on_train_batch_start,\n",
      "\ton_train_end, on_train_epoch_end, on_train_epoch_start, on_train_start,\n",
      "\ton_validation_batch_end, on_validation_batch_start, on_validation_end,\n",
      "\ton_validation_epoch_end, on_validation_epoch_start, on_validation_start\n"
     ]
    }
   ],
   "source": [
    "hooks = \", \".join([method for method in dir(pl.Callback) if method.startswith(\"on_\")])\n",
    "print(\"hooks:\", *textwrap.wrap(hooks, width=80), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelloWorldCallback(pl.Callback):\n",
    "\n",
    "    def on_train_epoch_start(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        print(\" hello from the start of the training epoch!\")\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        print(\" hello from the end of the validation epoch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def on_train_batch_start(self, trainer: pl.Trainer, pl_module: pl.LightningModule, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n",
    "        if random.random() > 0.995:\n",
    "            print(f\" hello from inside the lucky batch, #{batch_idx}!\")\n",
    "\n",
    "\n",
    "HelloWorldCallback.on_train_batch_start = on_train_batch_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "datamodule = CorrelatedDataModule()\n",
    "\n",
    "trainer = pl.Trainer(  # we instantiate and provide the callback here, but nothing happens yet\n",
    "    max_epochs=10, \n",
    "    accelerator='gpu',\n",
    "    devices=int(torch.cuda.is_available()),\n",
    "    callbacks=[HelloWorldCallback()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 2     \n",
      "---------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/home/stanley/miniconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [00:00<?, ?it/s] hello from the start of the training epoch!\n",
      "Epoch 0:   4%|         | 11/250 [00:00<00:01, 166.96it/s, v_num=11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|         | 14/250 [00:00<00:01, 155.41it/s, v_num=11] hello from inside the lucky batch, #14!\n",
      "Epoch 0:  52%|    | 130/250 [00:00<00:00, 143.90it/s, v_num=11] hello from inside the lucky batch, #130!\n",
      "Epoch 0:  88%| | 221/250 [00:01<00:00, 145.86it/s, v_num=11] hello from inside the lucky batch, #221!\n",
      "Epoch 0: 100%|| 250/250 [00:01<00:00, 146.37it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 1: 100%|| 250/250 [00:01<00:00, 156.55it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 2:  20%|        | 49/250 [00:00<00:01, 154.57it/s, v_num=11]  hello from inside the lucky batch, #49!\n",
      "Epoch 2:  34%|      | 86/250 [00:00<00:01, 152.63it/s, v_num=11] hello from inside the lucky batch, #86!\n",
      "Epoch 2: 100%|| 250/250 [00:01<00:00, 150.07it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 3:  34%|      | 84/250 [00:00<00:01, 151.88it/s, v_num=11]  hello from inside the lucky batch, #84!\n",
      "Epoch 3: 100%|| 250/250 [00:01<00:00, 147.26it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 4: 100%|| 250/250 [00:01<00:00, 148.43it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 5:  54%|    | 135/250 [00:00<00:00, 138.46it/s, v_num=11] hello from inside the lucky batch, #135!\n",
      "Epoch 5: 100%|| 250/250 [00:01<00:00, 145.17it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 6:  87%| | 217/250 [00:01<00:00, 149.97it/s, v_num=11] hello from inside the lucky batch, #217!\n",
      "Epoch 6: 100%|| 250/250 [00:01<00:00, 151.18it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 7: 100%|| 250/250 [00:01<00:00, 150.42it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 8:  74%|  | 186/250 [00:01<00:00, 152.50it/s, v_num=11] hello from inside the lucky batch, #186!\n",
      "Epoch 8: 100%|| 250/250 [00:01<00:00, 153.28it/s, v_num=11] hello from the start of the training epoch!\n",
      "Epoch 9:  69%|   | 172/250 [00:01<00:00, 144.35it/s, v_num=11] hello from inside the lucky batch, #172!\n",
      "Epoch 9: 100%|| 250/250 [00:01<00:00, 141.76it/s, v_num=11]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 250/250 [00:01<00:00, 141.20it/s, v_num=11]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_docs_url = f\"https://pytorch-lightning.readthedocs.io/en/{version}/extensions/callbacks.html\"\n",
    "callback_docs_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics:\n",
      "\tfunctional, Accuracy, AUROC, AveragePrecision, BLEUScore, BootStrapper,\n",
      "\tCalibrationError, CatMetric, ClasswiseWrapper, CharErrorRate, CHRFScore,\n",
      "\tConcordanceCorrCoef, CohenKappa, ConfusionMatrix, CosineSimilarity, CramersV,\n",
      "\tDice, TweedieDevianceScore, ErrorRelativeGlobalDimensionlessSynthesis,\n",
      "\tExactMatch, ExplainedVariance, ExtendedEditDistance, F1Score, FBetaScore,\n",
      "\tFleissKappa, HammingDistance, HingeLoss, JaccardIndex, KendallRankCorrCoef,\n",
      "\tKLDivergence, LogCoshError, MatchErrorRate, MatthewsCorrCoef, MaxMetric,\n",
      "\tMeanAbsoluteError, MeanAbsolutePercentageError, MeanMetric, MeanSquaredError,\n",
      "\tMeanSquaredLogError, Metric, MetricCollection, MetricTracker, MinkowskiDistance,\n",
      "\tMinMaxMetric, MinMetric, ModifiedPanopticQuality, MultioutputWrapper,\n",
      "\tMultitaskWrapper, MultiScaleStructuralSimilarityIndexMeasure, PanopticQuality,\n",
      "\tPearsonCorrCoef, PearsonsContingencyCoefficient, PermutationInvariantTraining,\n",
      "\tPerplexity, Precision, PrecisionAtFixedRecall, PrecisionRecallCurve,\n",
      "\tPeakSignalNoiseRatio, R2Score, Recall, RecallAtFixedPrecision,\n",
      "\tRelativeAverageSpectralError, RelativeSquaredError, RetrievalFallOut,\n",
      "\tRetrievalHitRate, RetrievalMAP, RetrievalMRR, RetrievalNormalizedDCG,\n",
      "\tRetrievalPrecision, RetrievalRecall, RetrievalRPrecision,\n",
      "\tRetrievalPrecisionRecallCurve, RetrievalRecallAtFixedPrecision, ROC,\n",
      "\tRootMeanSquaredErrorUsingSlidingWindow, RunningMean, RunningSum, SacreBLEUScore,\n",
      "\tSignalDistortionRatio, ScaleInvariantSignalDistortionRatio,\n",
      "\tScaleInvariantSignalNoiseRatio, SignalNoiseRatio, SpearmanCorrCoef, Specificity,\n",
      "\tSpecificityAtSensitivity, SpectralAngleMapper, SpectralDistortionIndex, SQuAD,\n",
      "\tStructuralSimilarityIndexMeasure, StatScores, SumMetric,\n",
      "\tSymmetricMeanAbsolutePercentageError, TheilsU, TotalVariation,\n",
      "\tTranslationEditRate, TschuprowsT, UniversalImageQualityIndex,\n",
      "\tWeightedMeanAbsolutePercentageError, WordErrorRate, WordInfoLost,\n",
      "\tWordInfoPreserved\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "tm_version = torchmetrics.__version__\n",
    "print(\"metrics:\", *textwrap.wrap(\", \".join(torchmetrics.__all__), width=80), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(torchmetrics.Metric, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Initialize self.  See help(type(self)) for accurate signature.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOSS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_cycle_max_lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_total_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_cycle_total_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_CYCLE_TOTAL_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/shidder/ml/FullStackDL/fsdl-2022-labs/lab02/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "BaseLitModel.__init__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
