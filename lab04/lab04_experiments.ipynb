{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlH0lCOttCs5"
   },
   "source": [
    "<img src=\"https://fsdl.me/logo-720-dark-horizontal\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUPRHaeetRnT"
   },
   "source": [
    "# Lab 04: Experiment Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bry3Hr-PcgDs"
   },
   "source": [
    "### What You Will Learn\n",
    "\n",
    "- How experiment management brings observability to ML model development\n",
    "- Which features of experiment management we use in developing the Text Recognizer\n",
    "- Workflows for using Weights & Biases in experiment management, including metric logging, artifact versioning, and hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs0LXXlCU6Ix"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkQiK7lkgeXm"
   },
   "source": [
    "If you're running this notebook on Google Colab,\n",
    "the cell below will run full environment setup.\n",
    "\n",
    "It should take about three minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVx7C7H0PIZC"
   },
   "outputs": [],
   "source": [
    "lab_idx = 4\n",
    "\n",
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "    # change into the lab directory\n",
    "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
    "\n",
    "    # allow \"hot-reloading\" of modules\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    # needed for inline plots in some contexts\n",
    "    %matplotlib inline\n",
    "\n",
    "    bootstrap.run = False  # change to True re-run setup\n",
    "    \n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab contains a large number of embedded iframes\n",
    "that benefit from having a wide window.\n",
    "The cell below makes the notebook as wide as your browser window\n",
    "if `full_width` is set to `True`.\n",
    "Full width is the default behavior in Colab,\n",
    "so this cell is intended to improve the viewing experience in other Jupyter environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "full_width = True\n",
    "frame_height = 720  # adjust for your screen\n",
    "\n",
    "if full_width:  # if we want the notebook to take up the whole width\n",
    "    # add styling to the notebook's HTML directly\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow along with a video walkthrough on YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"50%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://fsdl.me/2022-lab-04-video-embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6e54d01210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src=\"https://fsdl.me/2022-lab-04-video-embed\", width=\"50%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPoFCoEcC8SV"
   },
   "source": [
    "# Why experiment management?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand why we need experiment management for ML development,\n",
    "let's start by running an experiment.\n",
    "\n",
    "We'll train a new model on a new dataset,\n",
    "using the training script `training/run_experiment.py`\n",
    "introduced in [Lab 02a](https://fsdl.me/lab02a-colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a CNN encoder and Transformer decoder, as in\n",
    "[Lab 03](https://fsdl.me/lab03-colab),\n",
    "but with some changes so we can iterate faster.\n",
    "We'll operate on just single lines of text at a time (`--dataclass IAMLines`), as in\n",
    "[Lab02b](https://fsdl.me/lab02b-colab),\n",
    "and we'll use a smaller CNN (`--modelclass LineCNNTransformer`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dataset of images of handwritten text written on a form underneath a typewritten prompt.\n",
      "\n",
      "    \"The IAM Lines dataset, first published at the ICDAR 1999, contains forms of unconstrained handwritten text,\n",
      "    which were scanned at a resolution of 300dpi and saved as PNG images with 256 gray levels.\"\n",
      "    From http://www.fki.inf.unibe.ch/databases/iam-handwriting-database\n",
      "\n",
      "    Images are identified by their \"form ID\". These IDs are used to separate train, validation and test splits,\n",
      "    as keys for dictonaries returning label and image crop region data, and more.\n",
      "\n",
      "    The data split we will use is\n",
      "    IAM lines Large Writer Independent Text Line Recognition Task (LWITLRT): 9,862 text lines.\n",
      "        The validation set has been merged into the train set.\n",
      "        The train set has 7,101 lines from 326 writers.\n",
      "        The test set has 1,861 lines from 128 writers.\n",
      "        The text lines of all data sets are mutually exclusive, thus each writer has contributed to one set only.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from text_recognizer.data.iam import IAM  # base dataset of images of handwritten text\n",
    "from text_recognizer.data import IAMLines  # processed version split into individual lines\n",
    "from text_recognizer.models import LineCNNTransformer  # simple CNN encoder / Transformer decoder\n",
    "\n",
    "\n",
    "print(IAM.__doc__)\n",
    "\n",
    "# uncomment a line below for details on either class\n",
    "# IAMLines??  \n",
    "# LineCNNTransformer??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will train a model on 10% of the data for two epochs.\n",
    "\n",
    "It takes up to a few minutes to run on commodity hardware,\n",
    "including data download and preprocessing.\n",
    "As it's running, continue reading below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0  | model                     | LineCNNTransformer | 4.3 M \n",
      "1  | model.line_cnn            | LineCNN            | 1.6 M \n",
      "2  | model.embedding           | Embedding          | 21.2 K\n",
      "3  | model.fc                  | Linear             | 21.3 K\n",
      "4  | model.pos_encoder         | PositionalEncoding | 0     \n",
      "5  | model.transformer_decoder | TransformerDecoder | 2.6 M \n",
      "6  | train_acc                 | Accuracy           | 0     \n",
      "7  | val_acc                   | Accuracy           | 0     \n",
      "8  | test_acc                  | Accuracy           | 0     \n",
      "9  | val_cer                   | CharacterErrorRate | 0     \n",
      "10 | test_cer                  | CharacterErrorRate | 0     \n",
      "11 | loss_fn                   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.189    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict Disk Size: 17.23 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8359b95ad9524376b8d8d7ff49008db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad44c647413344b58184165623d2ec8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf36083ef71f4167887d76ef3cc836ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a6f30f4c7f446ca9d14daed151dc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best model saved at: /home/stanley/Documents/shidder/ml/fsdl-text-recognizer-2022-labs/lab04/training/logs/lightning_logs/version_1/epoch=0000-validation.loss=3.123-validation.cer=1.910.ckpt\n",
      "Restoring states from the checkpoint path at /home/stanley/Documents/shidder/ml/fsdl-text-recognizer-2022-labs/lab04/training/logs/lightning_logs/version_1/epoch=0000-validation.loss=3.123-validation.cer=1.910.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/stanley/Documents/shidder/ml/fsdl-text-recognizer-2022-labs/lab04/training/logs/lightning_logs/version_1/epoch=0000-validation.loss=3.123-validation.cer=1.910.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704b19fa229f4d82ba708da970996f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer             1.987679362297058\n",
      "        test/loss            3.205613374710083\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "CPU times: user 42.8 s, sys: 21.4 s, total: 1min 4s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "\n",
    "gpus = int(torch.cuda.is_available()) \n",
    "\n",
    "%run training/run_experiment.py --model_class LineCNNTransformer --data_class IAMLines \\\n",
    "  --loss transformer --batch_size 32 --gpus {gpus} --max_epochs 2 \\\n",
    "  --limit_train_batches 0.1 --limit_val_batches 0.1 --limit_test_batches 0.1 --log_every_n_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model trains, we're calculating lots of metrics --\n",
    "loss on training and validation, [character error rate](https://torchmetrics.readthedocs.io/en/v0.7.3/references/functional.html#char-error-rate-func) --\n",
    "and reporting them to the terminal.\n",
    "\n",
    "This is achieved by the built-in `.log` method\n",
    "([docs](https://pytorch-lightning.readthedocs.io/en/1.6.1/common/lightning_module.html#train-epoch-level-metrics))\n",
    "of the `LightningModule`,\n",
    "and it is a very straightforward way to get basic information about your experiment as it's running\n",
    "without leaving the context where you're running it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning to read\n",
    "[information from streaming numbers in the command line](http://www.quickmeme.com/img/45/4502c7603faf94c0e431761368e9573df164fad15f1bbc27fc03ad493f010dea.jpg)\n",
    "is something of a rite of passage for MLEs, but\n",
    "let's consider what we can't see here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We're missing all metric values except the most recent --\n",
    "we can see them as they stream in, but they're constantly overwritten.\n",
    "We also can't associate them with timestamps, steps, or epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We also don't see any system metrics.\n",
    "We can't see how much the GPU is being utilized, how much CPU RAM is free, or how saturated our I/O bandwidth is\n",
    "without launching a separate process.\n",
    "And even if we do, those values will also not be saved and timestamped,\n",
    "so we can't correlate them with other things during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we continue to run experiments, changing code and opening new terminals,\n",
    "even the information we have or could figure out now will disappear.\n",
    "Say you spot a weird error message during training,\n",
    "but your session ends and the stdout is gone,\n",
    "so you don't know exactly what it was.\n",
    "Can you recreate the error?\n",
    "Which git branch and commit were you on?\n",
    "Did you have any uncommitted changes? Which arguments did you pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Also, model checkpoints containing the parameter values have been saved to disk.\n",
    "Can we relate these checkpoints to their metrics, both in terms of accuracy and in terms of performance?\n",
    "As we run more and more experiments,\n",
    "we'll want to slice and dice them to see if,\n",
    "say, models with `--lr 0.001` are generally better or worse than models with `--lr 0.0001`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to save and log all of this information, and more, in order to make our model training\n",
    "[observable](https://docs.honeycomb.io/getting-started/learning-about-observability/) --\n",
    "in short, so that we can understand, make decisions about, and debug our model training\n",
    "by looking at logs and source code, without having to recreate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had to write the logging code we need to save this information ourselves, that'd put us in for a world of hurt:\n",
    "1. That's a lot of code that's not at the core of building an ML-powered system. Robustly saving version control information means becoming _very_ good with your VCS, which is less time spent on mastering the important stuff -- your data, your models, and your problem domain.\n",
    "2. It's very easy to forget to log something that you don't yet realize is going to be critical at some point. Data on network traffic, disk I/O, and GPU/CPU syncing is unimportant until suddenly your training has slowed to a crawl 12 hours into training and you can't figure out where the bottleneck is.\n",
    "3. Once you do start logging everything that's necessary, you might find it's not performant enough -- the code you wrote so you can debug performance issues is [tanking your performance](https://i.imgflip.com/6q54og.jpg).\n",
    "4. Just logging is not enough. The bytes of data need to be made legible to humans in a GUI and searchable via an API, or else they'll be too hard to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Experiment Tracking with Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, we don't have to. PyTorch Lightning integrates with other libraries for additional logging features,\n",
    "and it makes logging very easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.log` method of the `LightningModule` isn't just for logging to the terminal.\n",
    "\n",
    "It can also use a logger to push information elsewhere.\n",
    "\n",
    "By default, we use\n",
    "[TensorBoard](https://www.tensorflow.org/tensorboard)\n",
    "via the Lightning `TensorBoardLogger`,\n",
    "which has been saving results to the local disk.\n",
    "\n",
    "Let's find them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a sequence of bash commands to get the latest experiment's directory\n",
    "#  by hand, you can just copy and paste it from the terminal\n",
    "\n",
    "list_all_log_files = \"find training/logs/lightning_logs/\"  # find avoids issues ls has with \\n in filenames\n",
    "filter_to_folders = \"grep '_[0-9]*$'\"  # regex match on end of line\n",
    "sort_version_descending = \"sort -Vr\"  # uses \"version\" sorting (-V) and reverses (-r)\n",
    "take_first = \"head -n 1\"  # the first n elements, n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training/logs/lightning_logs/version_1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_log, = ! {list_all_log_files} | {filter_to_folders} | {sort_version_descending} | {take_first}\n",
    "latest_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 99M\n",
      "-rw-r--r-- 1 stanley stanley  50M Nov 18 16:48 'epoch=0000-validation.loss=3.123-validation.cer=1.910.ckpt'\n",
      "-rw-r--r-- 1 stanley stanley  50M Nov 18 16:48 'epoch=0001-validation.loss=3.109-validation.cer=1.910.ckpt'\n",
      "-rw-r--r-- 1 stanley stanley 1.4K Nov 18 16:48  events.out.tfevents.1700306262.zephyrus.99262.2\n",
      "-rw-r--r-- 1 stanley stanley  224 Nov 18 16:48  events.out.tfevents.1700306319.zephyrus.99262.3\n",
      "-rw-r--r-- 1 stanley stanley    3 Nov 18 16:47  hparams.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {latest_log}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view results, we need to launch a TensorBoard server --\n",
    "much like we need to launch a Jupyter server to use Jupyter notebooks.\n",
    "\n",
    "The cells below load an extension that lets you use TensorBoard inside of a notebook\n",
    "the same way you'd use it from the command line, and then launch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# same command works in terminal, with \"{arguments}\" replaced with values or \"$VARIABLES\"\n",
    "\n",
    "port = 11717  # pick an open port on your machine\n",
    "host = \"0.0.0.0\" # allow connections from the internet\n",
    "                 #   watch out! make sure you turn TensorBoard off\n",
    "\n",
    "%tensorboard --logdir {latest_log} --port {port} --host {host}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see some charts of metrics over time along with some charting controls.\n",
    "\n",
    "You can click around in this interface and explore it if you'd like,\n",
    "but in the next section, we'll see that there are better tools for experiment management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've run many experiments on this machine,\n",
    "you can see all of their results by pointing TensorBoard\n",
    "at the whole `lightning_logs` directory,\n",
    "rather than just one experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir training/logs/lightning_logs --port {port + 1} --host \"0.0.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large numbers of experiments, the management experience is not great --\n",
    "it's for example hard to go from a line in a chart to metadata about the experiment or metric depicted in that line.\n",
    "\n",
    "It's especially difficult to switch between types of experiments, to compare experiments run on different machines, or to collaborate with others,\n",
    "which are important workflows as applications mature and teams grow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is an independent service, so we need to make sure we turn it off when we're done. Just flip `done_with_tensorboard` to `True`.\n",
    "\n",
    "If you run into any issues with the above cells failing to launch,\n",
    "especially across iterations of this lab, run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard.manager\n",
    "\n",
    "# get the process IDs for all tensorboard instances\n",
    "pids = [tb.pid for tb in tensorboard.manager.get_all()]\n",
    "\n",
    "done_with_tensorboard = False\n",
    "\n",
    "if done_with_tensorboard:\n",
    "    # kill processes\n",
    "    for pid in pids:\n",
    "        !kill {pid} 2> /dev/null\n",
    "        \n",
    "    # remove the temporary files that sometimes persist, see https://stackoverflow.com/a/59582163\n",
    "    !rm -rf {tensorboard.manager._get_info_dir()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Management with Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we manage experiments when we hit the limits of local TensorBoard?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is powerful and flexible and very scalable,\n",
    "but running it requires engineering effort and babysitting --\n",
    "you're running a database, writing data to it,\n",
    "and layering a web application over it.\n",
    "\n",
    "This is a fairly common workflow for web developers,\n",
    "but not so much for ML engineers.\n",
    "\n",
    "You can avoid this with [tensorboard.dev](https://tensorboard.dev/),\n",
    "and it's as simple as running the command `tensorboard dev upload`\n",
    "pointed at your logging directory.\n",
    "\n",
    "But there are strict limits to this free service:\n",
    "1GB of tensor data and 1GB of binary data.\n",
    "A single Text Recognizer model checkpoint is ~100MB,\n",
    "and that's not particularly large for a useful model.\n",
    "\n",
    "Furthermore, all data is public,\n",
    "so if you upload the inputs and outputs of your model,\n",
    "anyone who finds the link can see them.\n",
    "\n",
    "Overall, tensorboard.dev works very well for certain academic and open projects\n",
    "but not for industrial ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid that narrow permissions and limits issue,\n",
    "you could use [git LFS](https://git-lfs.github.com/)\n",
    "to track the binary data and tensor data,\n",
    "which is more likely to be sensitive than metrics.\n",
    "\n",
    "The Hugging Face ecosystem uses TensorBoard and git LFS.\n",
    "\n",
    "It includes the Hugging Face Hub, a git server much like GitHub,\n",
    "but designed first and foremost for collaboration on models and datasets,\n",
    "rather than collaboration on code.\n",
    "For example, the Hugging Face Hub\n",
    "[will host TensorBoard alongside models](https://huggingface.co/docs/hub/tensorboard)\n",
    "and officially has\n",
    "[no storage limit](https://discuss.huggingface.co/t/is-there-a-size-limit-for-dataset-hosting/14861/4),\n",
    "avoiding the\n",
    "[bandwidth and storage pricing](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-storage-and-bandwidth-usage)\n",
    "that make using git LFS with GitHub expensive.\n",
    "\n",
    "However, we prefer to avoid mixing software version control and experiment management.\n",
    "\n",
    "First, using the Hub requires maintaining an additional git remote,\n",
    "which is a hard ask for many engineering teams.\n",
    "\n",
    "Secondly, git-style versioning is an awkward fit for logging --\n",
    "is it really sensible to create a new commit for each logging event while you're watching live?\n",
    "\n",
    "Instead, we prefer to use systems that solve experiment management with _databases_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple alternatives to TensorBoard + git LFS that fit this bill.\n",
    "The primary [open governance](https://www.ibm.com/blogs/cloud-computing/2016/10/27/open-source-open-governance/)\n",
    "tool is [MLflow](https://github.com/mlflow/mlflow/)\n",
    "and there are a number of\n",
    "[closed-governance and/or closed-source tools](https://www.reddit.com/r/MachineLearning/comments/q5g7m9/n_sagemaker_experiments_vs_comet_neptune_wandb_etc/).\n",
    "\n",
    "These tools generally avoid any need to worry about hosting\n",
    "(unless data governance rules require a self-hosted version).\n",
    "\n",
    "For a sampling of publicly-posted opinions on experiment management tools,\n",
    "see these discussions from Reddit:\n",
    "\n",
    "- r/mlops: [1](https://www.reddit.com/r/mlops/comments/uxieq3/is_weights_and_biases_worth_the_money/), [2](https://www.reddit.com/r/mlops/comments/sbtkxz/best_mlops_platform_for_2022/)\n",
    "- r/MachineLearning: [3](https://www.reddit.com/r/MachineLearning/comments/sqa36p/comment/hwls9px/?utm_source=share&utm_medium=web2x&context=3)\n",
    "\n",
    "Among these tools, the FSDL recommendation is\n",
    "[Weights & Biases](https://wandb.ai),\n",
    "which we believe offers\n",
    "- the best user experience, both in the Python SDKs and in the graphical interface\n",
    "- the best integrations with other tools,\n",
    "including\n",
    "[Lightning](https://docs.wandb.ai/guides/integrations/lightning) and\n",
    "[Keras](https://docs.wandb.ai/guides/integrations/keras),\n",
    "[Jupyter](https://docs.wandb.ai/guides/track/jupyter),\n",
    "and even\n",
    "[TensorBoard](https://docs.wandb.ai/guides/integrations/tensorboard),\n",
    "and\n",
    "- the best tools for collaboration.\n",
    "\n",
    "Below, we'll take care to point out which logging and management features\n",
    "are available via generic interfaces in Lightning and which are W&B-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use wandb to track machine learning work.\n",
      "\n",
      "The most commonly used functions/objects are:\n",
      "  - wandb.init — initialize a new run at the top of your training script\n",
      "  - wandb.config — track hyperparameters and metadata\n",
      "  - wandb.log — log metrics and media over time within your training loop\n",
      "\n",
      "For guides and examples, see https://docs.wandb.com/guides.\n",
      "\n",
      "For scripts and interactive notebooks, see https://github.com/wandb/examples.\n",
      "\n",
      "For reference documentation, see https://docs.wandb.com/ref/python.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "print(wandb.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding it to our experiment running code is extremely easy,\n",
    "relative to the features we get, which is\n",
    "one of the main selling points of W&B.\n",
    "\n",
    "We get most of our new experiment management features just by changing a single variable, `logger`, from\n",
    "`TensorboardLogger` to `WandbLogger`\n",
    "and adding two lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    if args.wandb:\n",
      "        logger = pl.loggers.WandbLogger(log_model=\"all\", save_dir=str(log_dir), job_type=\"train\")\n",
      "        logger.watch(model, log_freq=max(100, args.log_every_n_steps))\n",
      "        logger.log_hyperparams(vars(args))\n",
      "        experiment_dir = logger.experiment.dir\n",
      "    callbacks += [cb.ModelSizeLogger(), cb.LearningRateMonitor()]\n"
     ]
    }
   ],
   "source": [
    "!grep \"args.wandb\" -A 5 training/run_experiment.py | head -n 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see what each of these lines does for us below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this logger is built into and maintained by PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mWandbLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moffline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0manonymous\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mproject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlog_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0magg_key_funcs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0magg_default_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mWandbLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLightningLoggerBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Log using `Weights and Biases <https://docs.wandb.ai/integrations/lightning>`_.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    **Installation and set-up**\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Install with pip:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: bash\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        pip install wandb\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Create a `WandbLogger` instance:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        from pytorch_lightning.loggers import WandbLogger\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        wandb_logger = WandbLogger(project=\"MNIST\")\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Pass the logger instance to the `Trainer`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        trainer = Trainer(logger=wandb_logger)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    A new W&B run will be created when training starts if you have not created one manually before with `wandb.init()`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    **Log metrics**\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Log from :class:`~pytorch_lightning.core.lightning.LightningModule`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        class LitModule(LightningModule):\u001b[0m\n",
      "\u001b[0;34m            def training_step(self, batch, batch_idx):\u001b[0m\n",
      "\u001b[0;34m                self.log(\"train/loss\", loss)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Use directly wandb module:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        wandb.log({\"train/loss\": loss})\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    **Log hyper-parameters**\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Save :class:`~pytorch_lightning.core.lightning.LightningModule` parameters:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        class LitModule(LightningModule):\u001b[0m\n",
      "\u001b[0;34m            def __init__(self, *args, **kwarg):\u001b[0m\n",
      "\u001b[0;34m                self.save_hyperparameters()\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Add other config parameters:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # add one parameter\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.experiment.config[\"key\"] = value\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # add multiple parameters\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.experiment.config.update({key1: val1, key2: val2})\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # use directly wandb module\u001b[0m\n",
      "\u001b[0;34m        wandb.config[\"key\"] = value\u001b[0m\n",
      "\u001b[0;34m        wandb.config.update()\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    **Log gradients, parameters and model topology**\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Call the `watch` method for automatically tracking gradients:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # log gradients and model topology\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.watch(model)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # log gradients, parameter histogram and model topology\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.watch(model, log=\"all\")\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # change log frequency of gradients and parameters (100 steps by default)\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.watch(model, log_freq=500)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # do not log graph (in case of errors)\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.watch(model, log_graph=False)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The `watch` method adds hooks to the model which can be removed at the end of training:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.unwatch(model)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    **Log model checkpoints**\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Log model checkpoints at the end of training:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        wandb_logger = WandbLogger(log_model=True)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Log model checkpoints as they get created during training:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        wandb_logger = WandbLogger(log_model=\"all\")\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Custom checkpointing can be set up through :class:`~pytorch_lightning.callbacks.ModelCheckpoint`:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # log model only if `val_accuracy` increases\u001b[0m\n",
      "\u001b[0;34m        wandb_logger = WandbLogger(log_model=\"all\")\u001b[0m\n",
      "\u001b[0;34m        checkpoint_callback = ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\")\u001b[0m\n",
      "\u001b[0;34m        trainer = Trainer(logger=wandb_logger, callbacks=[checkpoint_callback])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `latest` and `best` aliases are automatically set to easily retrieve a model checkpoint:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # reference can be retrieved in artifacts panel\u001b[0m\n",
      "\u001b[0;34m        # \"VERSION\" can be a version (ex: \"v2\") or an alias (\"latest or \"best\")\u001b[0m\n",
      "\u001b[0;34m        checkpoint_reference = \"USER/PROJECT/MODEL-RUN_ID:VERSION\"\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # download checkpoint locally (if not already cached)\u001b[0m\n",
      "\u001b[0;34m        run = wandb.init(project=\"MNIST\")\u001b[0m\n",
      "\u001b[0;34m        artifact = run.use_artifact(checkpoint_reference, type=\"model\")\u001b[0m\n",
      "\u001b[0;34m        artifact_dir = artifact.download()\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # load checkpoint\u001b[0m\n",
      "\u001b[0;34m        model = LitModule.load_from_checkpoint(Path(artifact_dir) / \"model.ckpt\")\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    **Log media**\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Log text with:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # using columns and data\u001b[0m\n",
      "\u001b[0;34m        columns = [\"input\", \"label\", \"prediction\"]\u001b[0m\n",
      "\u001b[0;34m        data = [[\"cheese\", \"english\", \"english\"], [\"fromage\", \"french\", \"spanish\"]]\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.log_text(key=\"samples\", columns=columns, data=data)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # using a pandas DataFrame\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.log_text(key=\"samples\", dataframe=my_dataframe)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Log images with:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # using tensors, numpy arrays or PIL images\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.log_image(key=\"samples\", images=[img1, img2])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # adding captions\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.log_image(key=\"samples\", images=[img1, img2], caption=[\"tree\", \"person\"])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        # using file path\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.log_image(key=\"samples\", images=[\"img_1.jpg\", \"img_2.jpg\"])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    More arguments can be passed for logging segmentation masks and bounding boxes. Refer to\u001b[0m\n",
      "\u001b[0;34m    `Image Overlays documentation <https://docs.wandb.ai/guides/track/log/media#image-overlays>`_.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    **Log Tables**\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `W&B Tables <https://docs.wandb.ai/guides/data-vis>`_ can be used to log, query and analyze tabular data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    They support any type of media (text, image, video, audio, molecule, html, etc) and are great for storing,\u001b[0m\n",
      "\u001b[0;34m    understanding and sharing any form of data, from datasets to model predictions.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        columns = [\"caption\", \"image\", \"sound\"]\u001b[0m\n",
      "\u001b[0;34m        data = [[\"cheese\", wandb.Image(img_1), wandb.Audio(snd_1)], [\"wine\", wandb.Image(img_2), wandb.Audio(snd_2)]]\u001b[0m\n",
      "\u001b[0;34m        wandb_logger.log_table(key=\"samples\", columns=columns, data=data)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See Also:\u001b[0m\n",
      "\u001b[0;34m        - `Demo in Google Colab <http://wandb.me/lightning>`__ with hyperparameter search and model logging\u001b[0m\n",
      "\u001b[0;34m        - `W&B Documentation <https://docs.wandb.ai/integrations/lightning>`__\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m        name: Display name for the run.\u001b[0m\n",
      "\u001b[0;34m        save_dir: Path where data is saved (wandb dir by default).\u001b[0m\n",
      "\u001b[0;34m        offline: Run offline (data can be streamed later to wandb servers).\u001b[0m\n",
      "\u001b[0;34m        id: Sets the version, mainly used to resume a previous run.\u001b[0m\n",
      "\u001b[0;34m        version: Same as id.\u001b[0m\n",
      "\u001b[0;34m        anonymous: Enables or explicitly disables anonymous logging.\u001b[0m\n",
      "\u001b[0;34m        project: The name of the project to which this run will belong.\u001b[0m\n",
      "\u001b[0;34m        log_model: Log checkpoints created by :class:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint`\u001b[0m\n",
      "\u001b[0;34m            as W&B artifacts. `latest` and `best` aliases are automatically set.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            * if ``log_model == 'all'``, checkpoints are logged during training.\u001b[0m\n",
      "\u001b[0;34m            * if ``log_model == True``, checkpoints are logged at the end of training, except when\u001b[0m\n",
      "\u001b[0;34m              :paramref:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint.save_top_k` ``== -1``\u001b[0m\n",
      "\u001b[0;34m              which also logs every checkpoint during training.\u001b[0m\n",
      "\u001b[0;34m            * if ``log_model == False`` (default), no checkpoint is logged.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        prefix: A string to put at the beginning of metric keys.\u001b[0m\n",
      "\u001b[0;34m        experiment: WandB experiment object. Automatically set when creating a run.\u001b[0m\n",
      "\u001b[0;34m        \\**kwargs: Arguments passed to :func:`wandb.init` like `entity`, `group`, `tags`, etc.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Raises:\u001b[0m\n",
      "\u001b[0;34m        ModuleNotFoundError:\u001b[0m\n",
      "\u001b[0;34m            If required WandB package is not installed on the device.\u001b[0m\n",
      "\u001b[0;34m        MisconfigurationException:\u001b[0m\n",
      "\u001b[0;34m            If both ``log_model`` and ``offline`` is set to ``True``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mLOGGER_JOIN_CHAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msave_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moffline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0manonymous\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mproject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlog_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0magg_key_funcs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0magg_default_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwandb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"You want to use `wandb` logger which is not installed yet,\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\" install it with `pip install wandb`.\"\u001b[0m  \u001b[0;31m# pragma: no-cover\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0moffline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlog_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Providing log_model={log_model} and offline={offline} is an invalid configuration\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\" since model checkpoints cannot be uploaded in offline mode.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Hint: Set `offline=False` to log your model.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlog_model\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_WANDB_GREATER_EQUAL_0_10_22\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Providing log_model={log_model} requires wandb version >= 0.10.22\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\" for logging associated model metadata.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Hint: Upgrade with `pip install --upgrade wandb`.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_key_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_key_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_default_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_default_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffline\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_model\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_model_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# set wandb init arguments\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0manonymous_lut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"allow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manonymous_lut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manonymous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# extract parameters\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# start wandb run (to create an attach_id for distributed modes)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0m_WANDB_GREATER_EQUAL_0_12_10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"service\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# args needed to reload correct experiment\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_attach_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_attach_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# cannot be pickled\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_experiment\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_experiment\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Actual wandb object. To use wandb features in your\u001b[0m\n",
      "\u001b[0;34m        :class:`~pytorch_lightning.core.lightning.LightningModule` do the following.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Example::\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. code-block:: python\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            self.logger.experiment.some_wandb_function()\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"WANDB_MODE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dryrun\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mattach_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_attach_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# wandb process already created in this instance\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\" this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mattach_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_attach\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# attach to wandb process referenced\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattach_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# create new wandb process\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# define default x-axis\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"define_metric\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer/global_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"trainer/global_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_sync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradients\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_graph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlog_hyperparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_callable_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_val_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mrank_zero_only\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"experiment tried to log from global_rank != 0\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOGGER_JOIN_CHAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trainer/global_step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlog_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdataframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Log a Table containing any object type (text, image, audio, video, molecule, html, etc).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Can be defined either with `columns` and `data` or with `dataframe`.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlog_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdataframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Log text as a Table.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Can be defined either with `columns` and `data` or with `dataframe`.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlog_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Log images (tensors, numpy arrays, PIL Images or file paths).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Optional kwargs are lists passed to each image (ex: caption, masks, boxes).\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Expected a list as \"images\", found {type(images)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected {n} items but only found {len(v)} for {k}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkwarg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Gets the save directory.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m            The path to the save directory.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_dir\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Gets the name of the experiment.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m            The name of the experiment if the experiment exists else the name given to the constructor.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# don't create an experiment if we don't have one\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Gets the id of the experiment.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m            The id of the experiment if the experiment exists else the id given to the constructor.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# don't create an experiment if we don't have one\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mafter_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ReferenceType[ModelCheckpoint]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# log checkpoints as artifacts\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_top_k\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_and_log_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# log checkpoints as artifacts\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_and_log_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_scan_and_log_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ReferenceType[ModelCheckpoint]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# get checkpoints to be saved with associated score\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_model_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_k_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoints\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_model_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_model_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# log iteratively all new checkpoints\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"original_filename\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"ModelCheckpoint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"monitor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"save_last\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"save_top_k\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"save_weights_only\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                            \u001b[0;34m\"_every_n_train_steps\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;31m# ensure it does not break if `ModelCheckpoint` args change\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0m_WANDB_GREATER_EQUAL_0_10_22\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0martifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"model-{self.experiment.id}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maliases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"latest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"latest\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maliases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# remember logged models - timestamp needed in case filename didn't change (lastkckpt or custom name)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_model_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "WandbLogger??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete the rest of this notebook,\n",
    "you'll need a Weights & Biases account.\n",
    "\n",
    "As with GitHub the free tier, for personal, academic, and open source work,\n",
    "is very generous.\n",
    "\n",
    "The Text Recognizer project will fit comfortably within the free tier.\n",
    "\n",
    "Run the cell below and follow the prompts to log in or create an account or go\n",
    "[here](https://wandb.ai/signup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstanleyedward\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to launch an experiment tracked with Weights & Biases.\n",
    "\n",
    "The experiment can take between 3 and 10 minutes to run.\n",
    "In that time, continue reading below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "gpus = int(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstanleyedward\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>training/logs/wandb/run-20231118_221425-3xs7qvhy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04/runs/3xs7qvhy\" target=\"_blank\">pretty-donkey-2</a></strong> to <a href=\"https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0  | model                     | LineCNNTransformer | 4.3 M \n",
      "1  | model.line_cnn            | LineCNN            | 1.6 M \n",
      "2  | model.embedding           | Embedding          | 21.2 K\n",
      "3  | model.fc                  | Linear             | 21.3 K\n",
      "4  | model.pos_encoder         | PositionalEncoding | 0     \n",
      "5  | model.transformer_decoder | TransformerDecoder | 2.6 M \n",
      "6  | train_acc                 | Accuracy           | 0     \n",
      "7  | val_acc                   | Accuracy           | 0     \n",
      "8  | test_acc                  | Accuracy           | 0     \n",
      "9  | val_cer                   | CharacterErrorRate | 0     \n",
      "10 | test_cer                  | CharacterErrorRate | 0     \n",
      "11 | loss_fn                   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.189    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict Disk Size: 17.23 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce738a3dc364508b15305eeb231691d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.10/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cccfbf869d9470ebb65c94dfc548751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfef9f3d4cce45bfbeb3586bafb4e6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5e8b2a2c8842e4b6c9ff08c2fb55cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b386f86091464744b11752e3a3b6611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best model saved at: /home/stanley/Documents/shidder/ml/fsdl-text-recognizer-2022-labs/lab04/training/logs/lightning_logs/version_3/epoch=0002-validation.loss=2.804-validation.cer=1.780.ckpt\n",
      "Best model also uploaded to W&B \n",
      "Restoring states from the checkpoint path at /home/stanley/Documents/shidder/ml/fsdl-text-recognizer-2022-labs/lab04/training/logs/lightning_logs/version_3/epoch=0002-validation.loss=2.804-validation.cer=1.780.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/stanley/Documents/shidder/ml/fsdl-text-recognizer-2022-labs/lab04/training/logs/lightning_logs/version_3/epoch=0002-validation.loss=2.804-validation.cer=1.780.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9a3b1991b845bb853a539bcc59907c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer            1.8512637615203857\n",
      "        test/loss           2.8770124912261963\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f504b0018734a0a855d736ce6358fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='158.026 MB of 158.026 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▅▅▅▅█████</td></tr><tr><td>optimizer/lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>size/mb_disk</td><td>▁</td></tr><tr><td>size/nparams</td><td>▁</td></tr><tr><td>test/cer</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>train/loss</td><td>▆▄█▅█▄▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>validation/cer</td><td>██▁</td></tr><tr><td>validation/loss</td><td>██▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>optimizer/lr-Adam</td><td>0.001</td></tr><tr><td>size/mb_disk</td><td>17.22701</td></tr><tr><td>size/nparams</td><td>4297331</td></tr><tr><td>test/cer</td><td>1.85126</td></tr><tr><td>test/loss</td><td>2.87701</td></tr><tr><td>train/loss</td><td>3.10037</td></tr><tr><td>trainer/global_step</td><td>87</td></tr><tr><td>validation/cer</td><td>1.77968</td></tr><tr><td>validation/loss</td><td>2.80374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pretty-donkey-2</strong>: <a href=\"https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04/runs/3xs7qvhy\" target=\"_blank\">https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04/runs/3xs7qvhy</a><br/>Synced 5 W&B file(s), 13 media file(s), 399 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>training/logs/wandb/run-20231118_221425-3xs7qvhy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 34.4 s, total: 2min 9s\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%run training/run_experiment.py --model_class LineCNNTransformer --data_class IAMLines \\\n",
    "  --loss transformer --batch_size 32 --gpus {gpus} --max_epochs 3 \\\n",
    "  --log_every_n_steps 10 --wandb --limit_test_batches 0.1 \\\n",
    "  --limit_train_batches 0.1 --limit_val_batches 0.1\n",
    "    \n",
    "last_expt = wandb.run\n",
    "\n",
    "wandb.finish()  # necessary in this style of in-notebook experiment running, not necessary in CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some new things in our output.\n",
    "\n",
    "For example, there's a note from `wandb` that the data is saved locally\n",
    "and also synced to their servers.\n",
    "\n",
    "There's a link to a webpage for viewing the logged data and a name for our experiment --\n",
    "something like `dandy-sunset-1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local logging and cloud syncing happens with minimal impact on performance,\n",
    "because `wandb` launches a separate process to listen for events and upload them.\n",
    "\n",
    "That's a table-stakes feature for a logging framework but not a pleasant thing to write in Python yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view results, head to the link in the notebook output\n",
    "that looks like \"Syncing run **{adjective}-{noun}-{number}**\".\n",
    "\n",
    "There's no need to wait for training to finish.\n",
    "\n",
    "The next sections describe the contents of that interface. You can read them while looking at the W&B interface in a separate tab or window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For even more convenience, once training is finished we can also see the results directly in the notebook by embedding the webpage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04/runs/3xs7qvhy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04/runs/3xs7qvhy\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6e54d015d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(last_expt.url)\n",
    "IFrame(last_expt.url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have landed on the run page\n",
    "([docs](https://docs.wandb.ai/ref/app/pages/run-page)),\n",
    "which collects up all of the information for a single experiment into a collection of tabs.\n",
    "\n",
    "We'll work through these tabs from top to bottom.\n",
    "\n",
    "Each header is also a link to the documentation for a tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Overview tab](https://docs.wandb.ai/ref/app/pages/run-page#overview-tab)\n",
    "This tab has an icon that looks like `(i)` or 🛈.\n",
    "\n",
    "The top section of this tab has high-level information about our run:\n",
    "- Timing information, like start time and duration\n",
    "- System hardware, hostname, and basic environment info\n",
    "- Git repository link and state\n",
    "\n",
    "This information is collected and logged automatically.\n",
    "\n",
    "The section at the bottom contains configuration information, which here includes all CLI args or their defaults,\n",
    "and summary metrics.\n",
    "\n",
    "Configuration information is collected with `.log_hyperparams` in Lightning or `wandb.config` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Charts tab](https://docs.wandb.ai/ref/app/pages/run-page#charts-tab)\n",
    "\n",
    "This tab has a line plot icon, something like 📈.\n",
    "\n",
    "It's also the default page you land on when looking at a W&B run.\n",
    "\n",
    "Charts are generated for everything we `.log` from PyTorch Lightning. The charts here are interactive and editable, and changes persist.\n",
    "\n",
    "Unfurl the \"Gradients\" section in this tab to check out the gradient histograms. These histograms can be useful for debugging training instability issues.\n",
    "\n",
    "We were able to log these just by calling `wandb.watch` on our model. This is a W&B-specific feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [System tab](https://docs.wandb.ai/ref/app/pages/run-page#system-tab)\n",
    "This tab has computer chip icon.\n",
    "\n",
    "It contains\n",
    "- GPU metrics for all GPUs: temperature, [utilization](https://stackoverflow.com/questions/5086814/how-is-gpu-and-memory-utilization-defined-in-nvidia-smi-results), and memory allocation\n",
    "- CPU metrics: memory usage, utilization, thread counts\n",
    "- Disk and network I/O levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Model tab](https://docs.wandb.ai/ref/app/pages/run-page#model-tab)\n",
    "This tab has an undirected graph icon that looks suspiciously like a [pawnbrokers' symbol](https://en.wikipedia.org/wiki/Pawnbroker#:~:text=The%20pawnbrokers%27%20symbol%20is%20three,the%20name%20of%20Lombard%20banking.).\n",
    "\n",
    "The information here was also generated from `wandb.watch`, and includes parameter counts and input/output shapes for all layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Logs tab](https://docs.wandb.ai/ref/app/pages/run-page#logs-tab)\n",
    "This tab has an icon that looks like a stylized command prompt, `>_`.\n",
    "\n",
    "It contains information that was printed to the stdout.\n",
    "\n",
    "This tab is useful for, e.g., determining when exactly a warning or error message started appearing.\n",
    "\n",
    "Note that model summary information is printed here. We achieve this with a Lightning `Callback` called `ModelSummary`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    summary_callback = pl.callbacks.ModelSummary(max_depth=2)\n"
     ]
    }
   ],
   "source": [
    "!grep \"callbacks.ModelSummary\" training/run_experiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightning `Callback`s add extra \"nice-to-have\" engineering features to our model training.\n",
    "\n",
    "For more on Lightning `Callback`s, see\n",
    "[Lab 02a](https://fsdl.me/lab02a-colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Files tab](https://docs.wandb.ai/ref/app/pages/run-page#files-tab)\n",
    "This tab has a stylized document icon, something like 📄.\n",
    "\n",
    "You can use this tab to view any files saved with the `wandb.save`.\n",
    "\n",
    "For most uses, that style is deprecated in favor of `wandb.log_artifact`,\n",
    "which we'll discuss shortly.\n",
    "\n",
    "But a few pieces of information automatically collected by W&B end up in this tab.\n",
    "\n",
    "Some highlights:\n",
    "  - Much more detailed environment info: `conda-environment.yaml` and `requirements.txt`\n",
    "  - A `diff.patch` that represents the difference between the files in the `git` commit logged in the overview and the actual disk state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Artifacts tab](https://docs.wandb.ai/ref/app/pages/run-page#artifacts-tab)\n",
    "This tab has the database or [drum memory icon](https://stackoverflow.com/a/2822750), which looks like a cylinder of three stacked hockey pucks.\n",
    "\n",
    "This tab contains all of the versioned binary files, aka artifacts, associated with our run.\n",
    "\n",
    "We store two kinds of binary files\n",
    "  - `run_table`s of model inputs and outputs\n",
    "  - `model` checkpoints\n",
    "\n",
    "We get model checkpoints via the built-in Lightning `ModelCheckpoint` callback, which is not specific to W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
      "        save_top_k=5,\n",
      "        filename=filename_format,\n",
      "        monitor=goldstar_metric,\n",
      "        mode=\"min\",\n",
      "        auto_insert_metric_name=False,\n",
      "        dirpath=experiment_dir,\n",
      "        every_n_epochs=args.check_val_every_n_epoch,\n",
      "    )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!grep \"callbacks.ModelCheckpoint\" -A 9 training/run_experiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools for working with artifacts in W&B are powerful and complex, so we'll cover them in various places throughout this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Tables of Logged Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to the Charts tab,\n",
    "notice that we have model inputs and outputs logged in structured tables\n",
    "under the train, validation, and test sections.\n",
    "\n",
    "These tables are interactive as well\n",
    "([docs](https://docs.wandb.ai/guides/data-vis/log-tables)).\n",
    "They support basic exploratory data analysis and are compatible with W&B's collaboration features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to charts in our run page, these tables also have their own pages inside the W&B web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04/artifacts/run_table/run-3xs7qvhy-trainpredictions/v0/files/train/predictions.table.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/stanleyedward/fsdl-text-recognizer-2022-labs-lab04/artifacts/run_table/run-3xs7qvhy-trainpredictions/v0/files/train/predictions.table.json\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6e6c254100>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_versions_url = last_expt.url.split(\"runs\")[0] + f\"artifacts/run_table/run-{last_expt.id}-trainpredictions/\"\n",
    "table_data_url = table_versions_url + \"v0/files/train/predictions.table.json\"\n",
    "\n",
    "print(table_data_url)\n",
    "IFrame(src=table_data_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting this to work requires more effort and more W&B-specific code\n",
    "than the other features we've seen so far.\n",
    "\n",
    "We'll briefly explain the implementation here, for those who are interested.\n",
    "\n",
    "We use a custom Lightning `Callback`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.callbacks.imtotext import ImageToTextTableLogger\n",
    "\n",
    "\n",
    "ImageToTextTableLogger??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Lightning returns logged information on every batch and these outputs are accumulated throughout an epoch.\n",
    "\n",
    "The values are then aggregated with a frequency determined by the `pl.Trainer` argument `--log_every_n_batches`.\n",
    "\n",
    "This behavior is sensible for metrics, which are low overhead, but not so much for media,\n",
    "where we'd rather subsample and avoid holding on to too much information.\n",
    "\n",
    "So we additionally control when media is included in the outputs with methods like `add_on_logged_batches`.\n",
    "\n",
    "The frequency of media logging is then controlled with `--log_every_n_batches`, as with aggregate metric reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.lit_models.base import BaseImageToTextLitModel\n",
    "\n",
    "BaseImageToTextLitModel.add_on_logged_batches??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything we've seen so far has been related to a single run or experiment.\n",
    "\n",
    "Experiment management starts to shine when you can organize, filter, and group many experiments at once.\n",
    "\n",
    "We organize our runs into \"projects\" and view them on the  W&B \"project page\" \n",
    "([docs](https://docs.wandb.ai/ref/app/pages/project-page)).\n",
    "\n",
    "By default in the Lightning integration, the project name is determined based on directory information.\n",
    "This default can be over-ridden in the code when creating a `WandbLogger`,\n",
    "but we find it easier to change it from the command line by setting the `WANDB_PROJECT` environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the project page looks like for a longer-running project with lots of experiments.\n",
    "\n",
    "The cell below pulls up the project page for some of the debugging and feature addition work done while updating the course from 2021 to 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "project_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/workspace\"\n",
    "\n",
    "print(project_url)\n",
    "IFrame(src=project_url, width=\"100%\", height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page and these charts have been customized -- filtering down to the most interesting training runs and surfacing the most important high-level information about them.\n",
    "\n",
    "We welcome you to poke around in this interface: deactivate or change the filters, clicking through into individual runs, and change the charts around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond logging metrics and metadata from runs,\n",
    "we can also log and version large binary files, or artifacts, and their metadata ([docs](https://docs.wandb.ai/guides/artifacts/artifacts-core-concepts))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below pulls up all of the artifacts associated with the experiment we just ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IFrame(src=last_expt.url + \"/artifacts\", width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on one of the `model` checkpoints -- the specific version doesn't matter.\n",
    "\n",
    "There are a number of tabs here.\n",
    "\n",
    "The \"Overview\" tab includes automatically generated metadata, like which run by which user created this model checkpoint, when, and how much disk space it takes up.\n",
    "\n",
    "The \"Metadata\" tab includes configurable metadata, here hyperparameters and metrics like `validation/cer`,\n",
    "which are added by default by the `WandbLogger`.\n",
    "\n",
    "The \"Files\" tab contains the actual file contents of the artifact.\n",
    "\n",
    "On the left-hand side of the page, you'll see the other versions of the model checkpoint,\n",
    "including some versions that are \"tagged\" with version aliases, like `latest` or `best`.\n",
    "\n",
    "You can click on these to explore the different versions and even directly compare them.\n",
    "\n",
    "If you're particularly interested in this tool, try comparing two versions of the `validation-predictions` artifact, starting from the Files tab and clicking inside it to `validation/predictions.table.json`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artifact storage is part of the W&B free tier.\n",
    "\n",
    "The storage limits, as of August 2022, cover 100GB of Artifacts and experiment data.\n",
    "\n",
    "The former is sufficient to store ~700 model checkpoints for the Text Recognizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can track your data storage and compare it to your limits at this URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_tracker_url = f\"https://wandb.ai/usage/{last_expt.entity}\"\n",
    "\n",
    "print(storage_tracker_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmatic Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also programmatically access our data and metadata via the `wandb` API\n",
    "([docs](https://docs.wandb.ai/guides/track/public-api-guide)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can access the metrics we just logged as a `pandas.DataFrame` by grabbing the run via the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wb_api.run(\"/\".join( # fetch a run given\n",
    "    [last_expt.entity,     # the user or org it was logged to\n",
    "     last_expt.project,    # the \"project\", usually one of several per repo/application\n",
    "     last_expt.id]         # and a unique ID\n",
    "))\n",
    "\n",
    "hist = run.history()  # and pull down a sample of the data as a pandas DataFrame\n",
    "\n",
    "hist.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.groupby(\"epoch\")[\"train/loss\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this includes the artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which artifacts where created and logged?\n",
    "artifacts = run.logged_artifacts()\n",
    "\n",
    "for artifact in artifacts:\n",
    "    print(f\"artifact of type {artifact.type}: {artifact.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to our `ImageToTextTableLogger`,\n",
    "we can easily recreate training or validation data that came out of our `DataLoader`s,\n",
    "which is normally ephemeral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "artifact = wb_api.artifact(f\"{last_expt.entity}/{last_expt.project}/run-{last_expt.id}-trainpredictions:latest\")\n",
    "artifact_dir = Path(artifact.download(root=\"training/logs\"))\n",
    "image_dir = artifact_dir / \"media\" / \"images\"\n",
    "\n",
    "images = [path for path in image_dir.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(str(random.choice(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced W&B API Usage: MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the strengths of a well-instrumented experiment tracking system is that it allows\n",
    "automatic relation of information:\n",
    "what were the inputs when this model's gradient spiked?\n",
    "Which models have been trained on this dataset,\n",
    "and what was their performance?\n",
    "\n",
    "Having access and automation around this information is necessary for \"MLOps\",\n",
    "which applies contemporary DevOps principles to ML projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below pull down the training data\n",
    "for the model currently running the FSDL Text Recognizer app.\n",
    "\n",
    "This is just intended as a demonstration of what's possible,\n",
    "so don't worry about understanding every piece of this,\n",
    "and feel free to skip past it.\n",
    "\n",
    "MLOps is still a nascent field, and these tools and workflows are likely to change.\n",
    "\n",
    "For example, just before the course launched, W&B released a\n",
    "[Model Registry layer](https://docs.wandb.ai/guides/models)\n",
    "on top of artifact logging that aims to improve the developer experience for these workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from the same project we looked at in the project view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_recognizer_project = wb_api.project(\"fsdl-text-recognizer-2021-training\", entity=\"cfrye59\")\n",
    "\n",
    "text_recognizer_project  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we search it for the text recognizer model currently being used in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all versions of the text-recognizer ever put into production by...\n",
    "\n",
    "for art_type in text_recognizer_project.artifacts_types(): # looking through all artifact types\n",
    "    if art_type.name == \"prod-ready\":  # for the prod-ready type\n",
    "        # and grabbing the text-recognizer\n",
    "        production_text_recognizers = art_type.collection(\"paragraph-text-recognizer\").versions()\n",
    "\n",
    "# and then get the one that's currently being tested in CI by...\n",
    "for text_recognizer in production_text_recognizers:\n",
    "    if \"ci-test\" in text_recognizer.aliases:  # looking for the one that's labeled as CI-tested\n",
    "        in_prod_text_recognizer = text_recognizer\n",
    "\n",
    "# view its metadata at the url or in the notebook\n",
    "in_prod_text_recognizer_url = text_recognizer_project.url[:-9] + f\"artifacts/{in_prod_text_recognizer.type}/{in_prod_text_recognizer.name.replace(':', '/')}\"\n",
    "\n",
    "print(in_prod_text_recognizer_url)\n",
    "IFrame(src=in_prod_text_recognizer_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From its metadata, we can get information about how it was \"staged\" to be put into production,\n",
    "and in particular which model checkpoint was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_run = in_prod_text_recognizer.logged_by()\n",
    "\n",
    "training_ckpt, = [at for at in staging_run.used_artifacts() if at.type == \"model\"]\n",
    "training_ckpt.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That checkpoint was logged by a training experiment, which is available as metadata.\n",
    "\n",
    "We can look at the training run for that model, either here in the notebook or at its URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_run = training_ckpt.logged_by()\n",
    "print(training_run.url)\n",
    "IFrame(src=training_run.url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from there, we can access logs and metadata about training,\n",
    "confident that we are working with the model that is actually in production.\n",
    "\n",
    "For example, we can pull down the data we logged and analyze it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = training_run.history(samples=10000)\n",
    "training_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = training_results.groupby(\"epoch\")[\"train/loss\"].mean().plot();\n",
    "training_results[\"validation/loss\"].dropna().plot(logy=True); ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "training_results[\"validation/loss\"].dropna().iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The charts and webpages in Weights & Biases\n",
    "are substantially more useful than ephemeral stdouts or raw logs on disk.\n",
    "\n",
    "If you're spun up on the project,\n",
    "they accelerate debugging, exploration, and discovery.\n",
    "\n",
    "If not, they're not so much useful as they are overwhelming.\n",
    "\n",
    "We need to synthesize the raw logged data into information.\n",
    "This helps us communicate our work with other stakeholders,\n",
    "preserve knowledge and prevent repetition of work,\n",
    "and surface insights faster.\n",
    "\n",
    "These workflows are supported by the W&B Reports feature\n",
    "([docs here](https://docs.wandb.ai/guides/reports)),\n",
    "which mix W&B charts and tables with explanatory markdown text and embeds.\n",
    "\n",
    "Below are some common report patterns and\n",
    "use cases and examples of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the examples are from the FSDL Text Recognizer project.\n",
    "You can find more of them\n",
    "[here](https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/reports/-Report-of-Reports---VmlldzoyMjEwNDM5),\n",
    "where we've organized them into a report!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dashboards are a structured subset of the output from one or more experiments,\n",
    "designed for quickly surfacing issues or insights,\n",
    "like an accuracy or performance regression\n",
    "or a change in the data distribution.\n",
    "\n",
    "Use cases:\n",
    "- show the basic state of ongoing experiment\n",
    "- compare one experiment to another\n",
    "- select the most important charts so you can spin back up into context on a project more quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/reports/Training-Run-2022-06-02--VmlldzoyMTAyOTkw\"\n",
    "\n",
    "IFrame(src=dashboard_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Request Documentation Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most software codebases,\n",
    "pull requests are a key focal point\n",
    "for units of work that combine\n",
    "short-term communication and long-term information tracking.\n",
    "\n",
    "In ML codebases, it's more difficult to bring\n",
    "sufficient information together to make PRs as useful.\n",
    "At FSDL, we like to add documentary\n",
    "reports with one or a small number of charts\n",
    "that connect logged information in the experiment management system\n",
    "to state in the version control software.\n",
    "\n",
    "Use cases:\n",
    "- communication of results within a team, e.g. code review\n",
    "- record-keeping that links pull request pages to raw logged info and makes it discoverable\n",
    "- improving confidence in PR correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugfix_doc_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/reports/Overfit-Check-After-Refactor--VmlldzoyMDY5MjI1\"\n",
    "\n",
    "IFrame(src=bugfix_doc_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog Post Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sufficient effort, the logged data in the experiment management system\n",
    "can be made clear enough to be consumed,\n",
    "sufficiently contextualized to be useful outside the team, and\n",
    "even beautiful.\n",
    "\n",
    "The result is a report that's closer to a blog post than a dashboard or internal document.\n",
    "\n",
    "Use cases:\n",
    "- communication between teams or vertically in large organizations\n",
    "- external technical communication for branding and recruiting\n",
    "- attracting users or contributors\n",
    "\n",
    "Check out this example, from the Craiyon.ai / DALL·E Mini project, by FSDL alumnus\n",
    "[Boris Dayma](https://twitter.com/borisdayma)\n",
    "and others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dalle_mini_blog_url = \"https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-Mini-Explained-with-Demo--Vmlldzo4NjIxODA#training-dall-e-mini\"\n",
    "\n",
    "IFrame(src=dalle_mini_blog_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of our choices, like the depth of our network, the nonlinearities of our layers,\n",
    "and the learning rate and other parameters of our optimizer, cannot be\n",
    "([easily](https://arxiv.org/abs/1606.04474))\n",
    "chosen by descent of the gradient of a loss function.\n",
    "\n",
    "But these parameters that impact the values of the parameters\n",
    "we directly optimize with gradients, or _hyperparameters_,\n",
    "can still be optimized,\n",
    "essentially by trying options and selecting the values that worked best.\n",
    "\n",
    "In general, you can attain much of the benefit of hyperparameter optimization with minimal effort.\n",
    "\n",
    "Expending more compute can squeeze small amounts of additional validation or test performance\n",
    "that makes for impressive results on leaderboards but typically doesn't translate\n",
    "into better user experience.\n",
    "\n",
    "In general, the FSDL recommendation is to use the hyperparameter optimization workflows\n",
    "built into your other tooling.\n",
    "\n",
    "Weights & Biases makes the most straightforward forms of hyperparameter optimization trivially easy\n",
    "([docs](https://docs.wandb.ai/guides/sweeps)).\n",
    "\n",
    "It also supports a number of more advanced tools, like\n",
    "[Hyperband](https://docs.wandb.ai/guides/sweeps/configuration#early_terminate)\n",
    "for early termination of poorly-performing runs.\n",
    "\n",
    "We can use the same training script and we don't need to run an optimization server.\n",
    "\n",
    "We just need to write a configuration yaml file\n",
    "([docs](https://docs.wandb.ai/guides/sweeps/configuration)),\n",
    "like the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training/simple-overfit-sweep.yaml\n",
    "# first we specify what we're sweeping\n",
    "# we specify a program to run\n",
    "program: training/run_experiment.py\n",
    "# we optionally specify how to run it, including setting default arguments\n",
    "command:  \n",
    "    - ${env}\n",
    "    - ${interpreter}\n",
    "    - ${program}\n",
    "    - \"--wandb\"\n",
    "    - \"--overfit_batches\"\n",
    "    - \"1\"\n",
    "    - \"--log_every_n_steps\"\n",
    "    - \"25\"\n",
    "    - \"--max_epochs\"\n",
    "    - \"100\"\n",
    "    - \"--limit_test_batches\"\n",
    "    - \"0\"\n",
    "    - ${args}  # these arguments come from the sweep parameters below\n",
    "\n",
    "# and we specify which parameters to sweep over, what we're optimizing, and how we want to optimize it\n",
    "method: random  # generally, random searches perform well, can also be \"grid\" or \"bayes\"\n",
    "metric:\n",
    "    name: train/loss\n",
    "    goal: minimize\n",
    "parameters:  \n",
    "    # LineCNN hyperparameters\n",
    "    window_width:\n",
    "        values: [8, 16, 32, 64]\n",
    "    window_stride:\n",
    "        values: [4, 8, 16, 32]\n",
    "    # Transformer hyperparameters\n",
    "    tf_layers:\n",
    "        values: [1, 2, 4, 8]\n",
    "    # we can also fix some values, just like we set default arguments\n",
    "    gpus:\n",
    "        value: 1\n",
    "    model_class:\n",
    "        value: LineCNNTransformer\n",
    "    data_class:\n",
    "        value: IAMLines\n",
    "    loss:\n",
    "        value: transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the config we launch a \"controller\":\n",
    "a lightweight process that just decides what hyperparameters to try next\n",
    "and coordinates the heavierweight training.\n",
    "\n",
    "This lives on the W&B servers, so there are no headaches about opening ports for communication,\n",
    "cleaning up when it's done, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sweep training/simple-overfit-sweep.yaml --project fsdl-line-recognizer-2022\n",
    "simple_sweep_id = wb_api.project(\"fsdl-line-recognizer-2022\").sweeps()[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we can launch an \"agent\" to follow the orders of the controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# interrupt twice to terminate this cell if it's running too long,\n",
    "#   it can be over 15 minutes with some hyperparameters\n",
    "\n",
    "!wandb agent --project fsdl-line-recognizer-2022 --entity {wb_api.default_entity} --count=1 {simple_sweep_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell runs only a single experiment, because we provided the `--count` argument with a value of `1`.\n",
    "\n",
    "If not provided, the agent will run forever for random or Bayesian sweeps\n",
    "or until the sweep is terminated, which can be done from the W&B interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agents make for a slick workflow for distributing sweeps across GPUs.\n",
    "\n",
    "We can just change the `CUDA_VISIBLE_DEVICES` environment variable,\n",
    "which controls which GPUs are accessible by a process, to launch\n",
    "parallel agents on separate GPUs on the same machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CUDA_VISIBLE_DEVICES=0 wandb agent $SWEEP_ID\n",
    "# open another terminal\n",
    "CUDA_VISIBLE_DEVICES=1 wandb agent $SWEEP_ID\n",
    "# and so on\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFx-OhF837Bp"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include optional exercises with the labs for learners who want to dive deeper on specific topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌟Contribute to a hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've kicked off a big hyperparameter search on the `LineCNNTransformer` that anyone can join!\n",
    "\n",
    "There are ~10,000,000 potential hyperparameter combinations,\n",
    "and each takes 30 minutes to test,\n",
    "so checking each possibility will take over 500 years of compute time.\n",
    "Best get cracking then!\n",
    "\n",
    "Run the cell below to pull up a dashboard and print the URL where you can check on the current status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_entity = \"fullstackdeeplearning\"\n",
    "sweep_project = \"fsdl-line-recognizer-2022\"\n",
    "sweep_id = \"e0eo43eu\"\n",
    "sweep_url = f\"https://wandb.ai/{sweep_entity}/{sweep_project}/sweeps/{sweep_id}\"\n",
    "\n",
    "print(sweep_url)\n",
    "IFrame(src=sweep_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also retrieve information about the sweep from the API,\n",
    "including the hyperparameters being swept over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_info = wb_api.sweep(\"/\".join([sweep_entity, sweep_project, sweep_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = sweep_info.config[\"parameters\"]\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to contribute to this sweep,\n",
    "run the cell below after changing the count to a number greater than 0.\n",
    "\n",
    "Each iteration runs for 30 minutes if it does not crash,\n",
    "e.g. due to out-of-memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0  # off by default, increase it to join in!\n",
    "\n",
    "if count:\n",
    "    !wandb agent {sweep_id} --entity {sweep_entity} --project {sweep_project} --count {count}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5D39w0gXAiha"
   },
   "source": [
    "### 🌟🌟 Write some manual logging in `wandb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the FSDL Text Recognizer codebase,\n",
    "we almost exclusively log to W&B through Lightning,\n",
    "rather than through the `wandb` Python SDK.\n",
    "\n",
    "If you're interested in learning how to use W&B directly, e.g. with another training framework,\n",
    "try out this quick exercise that introduces the key players in the SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below starts a run with `wandb.init` and provides configuration hyperparameters with `wandb.config`.\n",
    "\n",
    "It also calculates a `loss` value and saves a text file, `logs/hello.txt`.\n",
    "\n",
    "Add W&B metric and artifact logging to this cell:\n",
    "- use [`wandb.log`](https://docs.wandb.ai/guides/track/log) to log the loss on each step\n",
    "- use [`wandb.log_artifact`](https://docs.wandb.ai/guides/artifacts) to save `logs/hello.txt` in an artifact with the name `hello` and whatever type you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "project = \"trying-wandb\"\n",
    "config = {\"steps\": 50}\n",
    "\n",
    "\n",
    "with wandb.init(project=project, config=config) as run:\n",
    "    steps = wandb.config[\"steps\"]\n",
    "    \n",
    "    for ii in range(steps):\n",
    "        loss = math.exp(-ii) + random.random() / (ii + 1)  # ML means making the loss go down\n",
    "        \n",
    "    with open(\"logs/hello.txt\", \"w\") as f:\n",
    "        f.write(\"hello from wandb, my dudes!\")\n",
    "        \n",
    "    run_id = run.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've correctly completed the exercise, the cell below will print only 🥞 emojis and no 🥲s before opening the run in an iframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_run = wb_api.run(f\"{project}/{run_id}\")\n",
    "\n",
    "# check for logged loss data\n",
    "if \"loss\" not in hello_run.history().keys():\n",
    "    print(\"loss not logged 🥲\")\n",
    "else:\n",
    "    print(\"loss logged successfully 🥞\")\n",
    "    if len(hello_run.history()[\"loss\"]) != steps:\n",
    "        print(\"loss not logged on all steps 🥲\")\n",
    "    else:\n",
    "        print(\"loss logged on all steps 🥞\")\n",
    "\n",
    "artifacts =  hello_run.logged_artifacts()\n",
    "\n",
    "# check for artifact with the right name\n",
    "if \"hello:v0\" not in [artifact.name for artifact in artifacts]:\n",
    "    print(\"hello artifact not logged 🥲\")\n",
    "else:\n",
    "    print(\"hello artifact logged successfully 🥞\")\n",
    "    # check for the file inside the artifacts\n",
    "    if \"hello.txt\" not in sum([list(artifact.manifest.entries.keys()) for artifact in artifacts], []):\n",
    "        print(\"could not find hello.txt 🥲\")\n",
    "    else:\n",
    "        print(\"hello.txt logged successfully 🥞\")\n",
    "    \n",
    "    \n",
    "hello_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5D39w0gXAiha"
   },
   "source": [
    "### 🌟🌟 Find good hyperparameters for the `LineCNNTransformer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default hyperparameters for the `LineCNNTransformer` are not particularly carefully tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try and find some better hyperparameters: choices that achieve a lower loss on the full dataset faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you observe interesting phenomena during training,\n",
    "from promising hyperparameter combos to software bugs to strange model behavior,\n",
    "turn the charts into a W&B report and share it with the FSDL community or\n",
    "[open an issue on GitHub](https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2022/issues)\n",
    "with a link to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the sweep_info.config above to see the model and data hyperparameters\n",
    "#   read through the --help output for all potential arguments\n",
    "%run training/run_experiment.py --model_class LineCNNTransformer --data_class IAMLines \\\n",
    "  --loss transformer --batch_size 32 --gpus {gpus} --max_epochs 5 \\\n",
    "  --log_every_n_steps 50 --wandb --limit_test_batches 0.1 \\\n",
    "  --limit_train_batches 0.1 --limit_val_batches 0.1 \\\n",
    "  --help  # remove this line to run an experiment instead of printing help\n",
    "    \n",
    "last_hyperparam_expt = wandb.run  # in case you want to pull URLs, look up in API, etc., as in code above\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌟🌟🌟 Add logging of tensor statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to logging model inputs and outputs as human-interpretable media,\n",
    "it's also frequently useful to see information about their numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in learning more about metric calculation and logging with Lightning,\n",
    "use [`torchmetrics`](https://torchmetrics.readthedocs.io/en/v0.7.3/)\n",
    "to add tensor statistic logging to the `LineCNNTransformer`.\n",
    "\n",
    "`torchmetrics` comes with built in statistical metrics, like `MinMetric`, `MaxMetric`, and `MeanMetric`.\n",
    "\n",
    "All three are useful, but start by adding just one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use your metric with `training/run_experiment.py`, you'll need to open and edit the `text_recognizer/lit_model/base.py` and `text_recognizer/lit_model/transformer.py` files\n",
    "- Add the metrics to the `BaseImageToTextLitModel`'s `__init__` method, around where `CharacterErrorRate` appears.\n",
    "  - You'll also need to decide whether to calculate separate train/validation/test versions. Whatever you do, start by implementing just one.\n",
    "- In the appropriate `_step` methods of the `TransformerLitModel`, add metric calculation and logging for `Min`, `Max`, and/or `Mean`.\n",
    "  - Base your code on the calculation and logging of the `val_cer` metric.\n",
    "  - `sync_dist=True` is only important in distributed training settings, so you might not notice any issues regardless of that argument's value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an extra challenge, use `MeanSquaredError` to implement a `VarianceMetric`. _Hint_: one way is to use `torch.zeros_like` and `torch.mean`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMKpeodqRUzgu0VjkCVMBeJ",
   "collapsed_sections": [],
   "name": "lab04_experiments.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
